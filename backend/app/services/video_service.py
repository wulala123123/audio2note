"""
æ–‡ä»¶å: video_service.py
åŠŸèƒ½æè¿°: è§†é¢‘å¤„ç†æ ¸å¿ƒæœåŠ¡ï¼Œå®ç° GPU åŠ é€Ÿçš„ PPT æå–ä¸éŸ³é¢‘è½¬å½•ç¼–æ’
æ ¸å¿ƒé€»è¾‘:
    - _locate_ppt_region(): ä½¿ç”¨ Canny è¾¹ç¼˜æ£€æµ‹å®šä½è§†é¢‘ä¸­çš„ PPT åŒºåŸŸ
    - _generate_lightweight_video(): ç”Ÿæˆè½»é‡è§†é¢‘ (640px, 5fps) ç”¨äºåŠ é€Ÿåˆ†æ
    - _run_funnel_analysis(): ä¸‰å±‚æ¼æ–— PPT æå– (L1å¸§å·® + L2æ¸…æ™°åº¦ + L3 OCRå»é‡)
    - _high_res_capture(): é«˜æ¸…å›æº¯ - ä»åŸè§†é¢‘æˆªå–æœ€ç»ˆç”»é¢
    - process(): ä¸»å…¥å£ï¼Œç¼–æ’ PPT æå–ä¸éŸ³é¢‘è½¬å½•ä¸¤ä¸ªç‹¬ç«‹æ¨¡å—

å…¨é“¾è·¯æ¶æ„ (Lightweight Media Workflow):
    1. Step 1.1: ROI Detection - å®šä½ PPT åŒºåŸŸ
    2. Step 1.2: Lightweight Video - ç”Ÿæˆè½»é‡è§†é¢‘ (640px, 5fps, å»éŸ³é¢‘)
    3. Step 1.3: Funnel Analysis - ä¸‰å±‚æ¼æ–—åˆ†æè½»é‡è§†é¢‘
       - L1: å¸§å·®æ£€æµ‹ (åœºæ™¯åˆ†å‰²)
       - L2: æ¸…æ™°åº¦æ‹©ä¼˜ (é€‰å† å†›å¸§)
       - L3: OCR è¯­ä¹‰å»é‡ (è¿‡æ»¤é‡å¤é¡µ + éPPTé¡µé¢)
    4. Step 1.4: High-Res Capture - ä»åŸè§†é¢‘é«˜æ¸…å›æº¯

è®¾è®¡äº®ç‚¹:
    - **Timestamp First**: æ‰€æœ‰é€»è¾‘åŸºäºæ—¶é—´æˆ³ (ç§’ float)ï¼Œä¸¥ç¦ä¾èµ– frame_index
    - è½»é‡è§†é¢‘åˆ†æ (å¿«é€Ÿ) + åŸè§†é¢‘æˆªå– (é«˜æ¸…) åˆ†ç¦»
    - Generator æ¨¡å¼æµå¼è¾“å‡ºï¼Œæ”¯æŒå®æ—¶è¿›åº¦æ›´æ–°
    - æµç¨‹ç»“æŸè‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶ (è½»é‡è§†é¢‘)
"""
import cv2
import shutil
from pathlib import Path
from typing import Tuple, Optional

from pptx import Presentation
from pptx.util import Inches
from loguru import logger

from app.core.config import OUTPUT_DIR, TEMP_DIR
from app.core.task_manager import update_task_progress
from app.services.audio_service import get_audio_transcriber
from app.services.gpu_frame_processor import GPUFrameProcessor, BestShot
from app.services.ocr_deduper import OCRDeduper
from app.utils.ffmpeg_utils import (
    generate_lightweight_video,
    extract_frame_at_timestamp,
    extract_frames_batch
)


class VideoService:
    """
    è§†é¢‘å¤„ç†æœåŠ¡ä¸»ç±»
    
    èŒè´£: ç¼–æ’æ•´ä¸ªè§†é¢‘ -> PPT è½¬æ¢æµç¨‹ï¼Œåè°ƒå„å­æ¨¡å—å·¥ä½œ
    
    æ ¸å¿ƒæµç¨‹ (Lightweight Media Workflow):
        1. å®šä½ PPT åŒºåŸŸ (ROI Detection)
        2. ç”Ÿæˆè½»é‡è§†é¢‘ (640px, 5fps)
        3. åœ¨è½»é‡è§†é¢‘ä¸Šè¿è¡Œä¸‰å±‚æ¼æ–—åˆ†æ
        4. ç”¨æ—¶é—´æˆ³å›æº¯åŸè§†é¢‘æˆªå–é«˜æ¸…ç”»é¢
    
    Attributes:
        output_guid: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºç»„ç»‡è¾“å‡ºç›®å½•
        base_output_path: ä»»åŠ¡è¾“å‡ºæ ¹ç›®å½•
        frame_processor: GPU å¸§å¤„ç†å™¨ (L1 + L2)
        ocr_deduper: OCR è¯­ä¹‰å»é‡å™¨ (L3)
    
    Example:
        >>> service = VideoService(output_guid="task-123")
        >>> result = service.process(Path("lecture.mp4"), enable_ppt_extraction=True)
        >>> print(result["ppt_file"])
    """
    
    def __init__(self, output_guid: str) -> None:
        """
        åˆå§‹åŒ–è§†é¢‘å¤„ç†æœåŠ¡
        
        Args:
            output_guid: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦ (é€šå¸¸ä¸º UUID)
        """
        self.output_guid = output_guid
        self.base_output_path = OUTPUT_DIR / output_guid
        
        # å®šä¹‰å­ç›®å½•ç»“æ„
        # è½»é‡è§†é¢‘ä¸´æ—¶ç›®å½•ï¼šæ”¾å…¥ temp ä¸‹ï¼Œæµç¨‹ç»“æŸåè‡ªåŠ¨æ¸…ç†
        self.temp_video_dir = TEMP_DIR / output_guid
        self.debug_images_dir = self.base_output_path / "debug_images"
        self.ppt_images_dir = self.base_output_path / "ppt_images"
        self.ppt_output_dir = self.base_output_path / "ppt_output"
        self.transcripts_dir = self.base_output_path / "transcripts"
        
        # åˆ›å»ºæ‰€éœ€æ–‡ä»¶å¤¹
        for p in [self.temp_video_dir, self.debug_images_dir, 
                  self.ppt_images_dir, self.ppt_output_dir, self.transcripts_dir]:
            p.mkdir(parents=True, exist_ok=True)
        
        logger.debug(f"ğŸ“ è¾“å‡ºç›®å½•å·²åˆ›å»º: {self.base_output_path}")
        logger.debug(f"ğŸ“ ä¸´æ—¶ç›®å½•å·²åˆ›å»º: {self.temp_video_dir}")
        
        # ========== åˆå§‹åŒ– GPU å¤„ç†å™¨ (L1 + L2) ==========
        # å‚æ•°è¯´æ˜:
        #   diff_threshold: å¸§é—´å·®å¼‚é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è§†ä¸ºåœºæ™¯åˆ‡æ¢
        #   min_scene_duration: åœºæ™¯æœ€çŸ­æŒç»­æ—¶é—´ï¼Œè¿‡æ»¤åŠ¨æ€è§†é¢‘ç‰‡æ®µ
        #   sample_interval: é‡‡æ ·é—´éš” (ç§’)ï¼Œæ¯ 0.2 ç§’å–ä¸€æ¬¡æ · (æ¯ç§’ 5 ä¸ªç‚¹)
        self.frame_processor = GPUFrameProcessor(
            diff_threshold=0.05,
            min_scene_duration=1,
            sample_interval=0.2  # æ¯ 0.2 ç§’é‡‡æ ·ä¸€æ¬¡
        )
        
        # ========== åˆå§‹åŒ– OCR å»é‡å™¨ (L3) ==========
        # å‚æ•°è¯´æ˜:
        #   similarity_threshold: æ–‡æœ¬ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶…è¿‡åˆ™åˆ¤å®šä¸ºé‡å¤é¡µ
        self.ocr_deduper = OCRDeduper(
            similarity_threshold=0.90
        )

    def process(
        self, 
        input_video_path: Path, 
        enable_ppt_extraction: bool = True,
        enable_audio_transcription: bool = True
    ) -> dict:
        """
        è§†é¢‘å¤„ç†ä¸»å…¥å£: ç¼–æ’ PPT æå–ä¸éŸ³é¢‘è½¬å½•ä¸¤ä¸ªç‹¬ç«‹æ¨¡å—
        
        ä¸¤ä¸ªåŠŸèƒ½æ¨¡å—å®Œå…¨è§£è€¦ï¼Œå¯ç‹¬ç«‹å¯ç”¨æˆ–åŒæ—¶å¯ç”¨ã€‚
        è¿›åº¦æ¡ä¼šæ ¹æ®å¯ç”¨çš„æ¨¡å—æ•°é‡è‡ªåŠ¨åˆ†é…åŒºé—´ã€‚
        
        Args:
            input_video_path: åŸå§‹è§†é¢‘æ–‡ä»¶è·¯å¾„
            enable_ppt_extraction: æ˜¯å¦æ‰§è¡Œ PPT æå–æµç¨‹ (é»˜è®¤ True)
            enable_audio_transcription: æ˜¯å¦æ‰§è¡ŒéŸ³é¢‘è½¬å½•æµç¨‹ (é»˜è®¤ True)
            
        Returns:
            dict: å¤„ç†ç»“æœï¼ŒåŒ…å«å„è¾“å‡ºæ–‡ä»¶è·¯å¾„
                - guid: ä»»åŠ¡ ID
                - ppt_file: PPT æ–‡ä»¶è·¯å¾„ (å¦‚å¯ç”¨ PPT æå–)
                - transcript_file: è½¬å½•æ–‡ä»¶è·¯å¾„ (å¦‚å¯ç”¨éŸ³é¢‘è½¬å½•)
        
        Raises:
            ValueError: PPT åŒºåŸŸå®šä½å¤±è´¥æˆ–è§†é¢‘è£å‰ªå¤±è´¥
        """
        input_video_path = Path(input_video_path)
        
        logger.info("=" * 50)
        logger.info(f"ğŸ¬ VideoService.process() å¼€å§‹å¤„ç†")
        logger.info(f"   ğŸ“‚ è¾“å…¥: {input_video_path.name}")
        logger.info(f"   ğŸ†” GUID: {self.output_guid}")
        logger.info(f"   ğŸ“Š PPTæå–: {enable_ppt_extraction} | ğŸ¤ éŸ³é¢‘è½¬å½•: {enable_audio_transcription}")
        logger.info("=" * 50)
        
        ppt_path = None
        transcript_path = None
        
        # ============================================================
        #               æ¨¡å— 1: PPT æå– (æ¡ä»¶æ‰§è¡Œ)
        # ============================================================
        if enable_ppt_extraction:
            logger.info("ğŸ“Š [PPT æå–æ¨¡å—] å¼€å§‹æ‰§è¡Œ (Lightweight Media Workflow)...")
            
            # è¿›åº¦åŒºé—´åˆ†é…:
            #   - è‹¥åŒæ—¶å¯ç”¨éŸ³é¢‘: PPT å  0-85%, éŸ³é¢‘å  85-100%
            #   - è‹¥ä»… PPT: PPT å  0-100%
            ppt_progress_end = 85 if enable_audio_transcription else 100
            
            # ----- Step 1.1: å®šä½ PPT åŒºåŸŸ -----
            update_task_progress(self.output_guid, 5, "æ­£åœ¨å®šä½ PPT åŒºåŸŸ...")
            logger.info("ğŸ” Step 1.1: å®šä½ PPT åŒºåŸŸ (Canny è¾¹ç¼˜æ£€æµ‹)")
            
            bbox = self._locate_ppt_region(input_video_path)
            
            if not bbox:
                logger.error("âŒ æ— æ³•å®šä½ PPT åŒºåŸŸ")
                raise ValueError("æ— æ³•å®šä½ PPT åŒºåŸŸï¼Œè¯·ç¡®ä¿è§†é¢‘ä¸­åŒ…å«æ¸…æ™°çš„ PPT ç”»é¢")
            
            logger.success(f"âœ… PPT åŒºåŸŸå®šä½æˆåŠŸ: x={bbox[0]}, y={bbox[1]}, w={bbox[2]}, h={bbox[3]}")
            
            # ----- Step 1.2: ç”Ÿæˆè½»é‡è§†é¢‘ -----
            update_task_progress(self.output_guid, 10, "æ­£åœ¨ç”Ÿæˆè½»é‡è§†é¢‘ (GPU åŠ é€Ÿ)...")
            logger.info("ğŸ¥ Step 1.2: ç”Ÿæˆè½»é‡è§†é¢‘ (640px, 5fps)")
            
            lightweight_video_path = self._generate_lightweight_video(input_video_path, bbox)
            
            if not lightweight_video_path:
                logger.error("âŒ è½»é‡è§†é¢‘ç”Ÿæˆå¤±è´¥")
                raise ValueError("è½»é‡è§†é¢‘ç”Ÿæˆå¤±è´¥")
            
            logger.success(f"âœ… è½»é‡è§†é¢‘ç”Ÿæˆå®Œæˆ: {lightweight_video_path.name}")
            
            # ----- Step 1.3: ä¸‰å±‚æ¼æ–—åˆ†æ -----
            update_task_progress(self.output_guid, 25, "æ­£åœ¨è¿›è¡Œä¸‰å±‚æ¼æ–—åˆ†æ...")
            logger.info("ğŸ¯ Step 1.3: ä¸‰å±‚æ¼æ–—åˆ†æ (L1â†’L2â†’L3)")
            
            final_timestamps = self._run_funnel_analysis(lightweight_video_path)
            
            logger.info(f"ğŸ“Š æ¼æ–—åˆ†æç»“æœ: å…± {len(final_timestamps)} ä¸ªæœ‰æ•ˆæ—¶é—´ç‚¹")
            
            if not final_timestamps:
                logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•æœ‰æ•ˆ PPT é¡µé¢")
                ppt_path = None
            else:
                # ----- Step 1.4: é«˜æ¸…å›æº¯ -----
                update_task_progress(self.output_guid, 70, "æ­£åœ¨é«˜æ¸…å›æº¯æˆªå–...")
                logger.info("ğŸ“¸ Step 1.4: é«˜æ¸…å›æº¯ (ä»åŸè§†é¢‘æˆªå–)")
                
                ppt_path = self._high_res_capture(
                    source_video=input_video_path,
                    timestamps=final_timestamps,
                    crop_bbox=bbox
                )
                
                if ppt_path:
                    logger.success(f"âœ… PPT ç”Ÿæˆå®Œæˆ: {ppt_path.name}")
                else:
                    logger.warning("âš ï¸ PPT ç”Ÿæˆå¤±è´¥")
        
        # ============================================================
        #               æ¨¡å— 2: éŸ³é¢‘è½¬å½• (æ¡ä»¶æ‰§è¡Œï¼Œå®Œå…¨ç‹¬ç«‹)
        # ============================================================
        if enable_audio_transcription:
            logger.info("ğŸ¤ [éŸ³é¢‘è½¬å½•æ¨¡å—] å¼€å§‹æ‰§è¡Œ...")
            
            # è¿›åº¦åŒºé—´:
            #   - è‹¥åŒæ—¶å¯ç”¨ PPT: ä» 85% å¼€å§‹
            #   - è‹¥ä»…éŸ³é¢‘: ä» 0% å¼€å§‹
            audio_progress_start = 85 if enable_ppt_extraction else 0
            
            update_task_progress(
                self.output_guid, 
                audio_progress_start + 5, 
                "æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ« (FunASR)..."
            )
            
            try:
                logger.info("ğŸ”Š è°ƒç”¨ FunASR è¿›è¡Œæœ¬åœ°è¯­éŸ³è¯†åˆ«...")
                transcript_text = get_audio_transcriber().transcribe_video(input_video_path)
                
                if transcript_text:
                    transcript_path = self.transcripts_dir / f"{self.output_guid}.txt"
                    with open(transcript_path, "w", encoding="utf-8") as f:
                        f.write(transcript_text)
                    logger.success(f"âœ… è½¬å½•æ–‡ä»¶å·²ä¿å­˜: {transcript_path.name}")
                    logger.debug(f"   ğŸ“ è½¬å½•å†…å®¹é¢„è§ˆ: {transcript_text[:100]}...")
                else:
                    logger.warning("âš ï¸ è½¬å½•ç»“æœä¸ºç©º")
                    
            except Exception as e:
                logger.exception(f"âŒ éŸ³é¢‘è½¬å½•è¿‡ç¨‹å‡ºé”™: {e}")
        
        # ============================================================
        #               æµç¨‹ç»“æŸ: æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        # ============================================================
        self._cleanup_temp_files()
        
        # ========== è¿”å›ç»“æœ ==========
        result = {
            "guid": self.output_guid,
            "ppt_file": str(ppt_path) if ppt_path else None,
            "transcript_file": str(transcript_path) if transcript_path else None
        }
        
        update_task_progress(self.output_guid, 100, "å¤„ç†å®Œæˆ")
        
        logger.info("=" * 50)
        logger.info(f"ğŸ VideoService.process() å¤„ç†å®Œæˆ")
        logger.info(f"   ğŸ“„ PPT: {'âœ… ' + ppt_path.name if ppt_path else 'âŒ æœªç”Ÿæˆ'}")
        logger.info(f"   ğŸ“ è½¬å½•: {'âœ… ' + transcript_path.name if transcript_path else 'âŒ æœªç”Ÿæˆ'}")
        logger.info("=" * 50)
        
        return result

    def _cleanup_temp_files(self) -> None:
        """
        æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        
        åœ¨å¤„ç†æµç¨‹ç»“æŸåè°ƒç”¨ï¼Œåˆ é™¤è½»é‡è§†é¢‘ç­‰ä¸´æ—¶æ–‡ä»¶ã€‚
        """
        try:
            if self.temp_video_dir.exists():
                shutil.rmtree(self.temp_video_dir)
                logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {self.temp_video_dir}")
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")

    def _locate_ppt_region(self, video_path: Path) -> Tuple[int, int, int, int] | None:
        """
        å®šä½è§†é¢‘ä¸­çš„ PPT åŒºåŸŸ (è¾¹ç¼˜æ£€æµ‹æ³•)
        
        ç®—æ³•ç­–ç•¥:
            1. åœ¨è§†é¢‘ 20%/40%/60% ä½ç½®å„é‡‡æ ·ä¸€å¸§
            2. ä½¿ç”¨ Canny è¾¹ç¼˜æ£€æµ‹è¯†åˆ«è¾¹ç¼˜
            3. ä½¿ç”¨è½®å»“åˆ†æå¯»æ‰¾æœ€å¤§å››è¾¹å½¢åŒºåŸŸ
            4. è¿”å›è¯¥åŒºåŸŸçš„ bounding box
        
        Why å¤šç‚¹é‡‡æ ·?
            - è§†é¢‘å¼€å¤´/ç»“å°¾å¯èƒ½æ²¡æœ‰ PPT ç”»é¢
            - å¤šç‚¹é‡‡æ ·æé«˜æ£€æµ‹æˆåŠŸç‡
        
        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            
        Returns:
            tuple: (x, y, w, h) PPT åŒºåŸŸåæ ‡å’Œå°ºå¯¸ï¼Œå¤±è´¥è¿”å› None
        """
        logger.debug(f"ğŸ” å¼€å§‹å®šä½ PPT åŒºåŸŸ: {video_path.name}")
        
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            logger.error(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return None
        
        try:
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            sample_points = [0.2, 0.4, 0.6]  # é‡‡æ ·ç‚¹: 20%, 40%, 60%
            
            logger.debug(f"   ğŸ“Š æ€»å¸§æ•°: {total_frames}, é‡‡æ ·ç‚¹: {sample_points}")
            
            for point in sample_points:
                frame_idx = int(total_frames * point)
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                
                if not ret:
                    logger.warning(f"   âš ï¸ é‡‡æ ·ç‚¹ {point:.0%} è¯»å–å¤±è´¥")
                    continue
                
                logger.debug(f"   ğŸ–¼ï¸ åˆ†æé‡‡æ ·ç‚¹ {point:.0%} (å¸§ {frame_idx})")
                
                # ä¿å­˜è°ƒè¯•å›¾åƒ (å¯è§†åŒ–è¾¹ç¼˜æ£€æµ‹è¿‡ç¨‹)
                cv2.imwrite(str(self.debug_images_dir / "0_original.jpg"), frame)
                
                # ----- Canny è¾¹ç¼˜æ£€æµ‹æµæ°´çº¿ -----
                # Step 1: BGR -> Gray (å‡å°‘è®¡ç®—é‡)
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                cv2.imwrite(str(self.debug_images_dir / "1_gray.jpg"), gray)
                
                # Step 2: é«˜æ–¯æ¨¡ç³Š (å»å™ªï¼Œå¹³æ»‘è¾¹ç¼˜)
                blurred = cv2.GaussianBlur(gray, (5, 5), 0)
                
                # Step 3: Canny è¾¹ç¼˜æ£€æµ‹
                # Why (30, 120)? ä½é˜ˆå€¼ 30 æ£€æµ‹å¼±è¾¹ç¼˜ï¼Œé«˜é˜ˆå€¼ 120 è¿‡æ»¤å™ªç‚¹
                edged = cv2.Canny(blurred, 30, 120)
                cv2.imwrite(str(self.debug_images_dir / "2_edged.jpg"), edged)
                
                # ----- è½®å»“åˆ†æ -----
                contours, _ = cv2.findContours(
                    edged.copy(), 
                    cv2.RETR_EXTERNAL,      # åªæ£€æµ‹å¤–è½®å»“
                    cv2.CHAIN_APPROX_SIMPLE  # å‹ç¼©è½®å»“ç‚¹
                )
                
                if not contours:
                    logger.debug(f"   âš ï¸ é‡‡æ ·ç‚¹ {point:.0%} æœªæ‰¾åˆ°è½®å»“")
                    continue
                
                # å–é¢ç§¯æœ€å¤§çš„ 5 ä¸ªè½®å»“ (PPT é€šå¸¸æ˜¯æœ€å¤§çš„çŸ©å½¢åŒºåŸŸ)
                contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]
                
                for c in contours:
                    # è½®å»“è¿‘ä¼¼: å‡å°‘é¡¶ç‚¹æ•°é‡
                    peri = cv2.arcLength(c, True)
                    approx = cv2.approxPolyDP(c, 0.03 * peri, True)
                    
                    # ç­›é€‰æ¡ä»¶:
                    #   1. å¿…é¡»æ˜¯ 4 è¾¹å½¢ (PPT æ˜¯çŸ©å½¢)
                    #   2. é¢ç§¯å æ¯” > 10% (è¿‡æ»¤å°åŒºåŸŸ)
                    frame_area = frame.shape[0] * frame.shape[1]
                    area_ratio = cv2.contourArea(c) / frame_area
                    
                    if len(approx) == 4 and area_ratio > 0.1:
                        # ä¿å­˜è°ƒè¯•ç»“æœ
                        debug_img = frame.copy()
                        cv2.drawContours(debug_img, [approx], -1, (0, 255, 0), 3)
                        cv2.imwrite(str(self.debug_images_dir / "3_final_region.jpg"), debug_img)
                        
                        bbox = cv2.boundingRect(approx)
                        logger.info(f"   âœ… åœ¨é‡‡æ ·ç‚¹ {point:.0%} æ‰¾åˆ° PPT åŒºåŸŸ")
                        logger.info(f"      ğŸ“ Bounding Box: x={bbox[0]}, y={bbox[1]}, w={bbox[2]}, h={bbox[3]}")
                        logger.info(f"      ğŸ“Š é¢ç§¯å æ¯”: {area_ratio:.1%}")
                        return bbox
            
            logger.error("âŒ æ‰€æœ‰é‡‡æ ·ç‚¹å‡æœªæ‰¾åˆ°æœ‰æ•ˆ PPT åŒºåŸŸ")
            return None
            
        finally:
            cap.release()

    def _generate_lightweight_video(
        self, 
        source_video: Path, 
        crop_bbox: Tuple[int, int, int, int]
    ) -> Optional[Path]:
        """
        ç”Ÿæˆè½»é‡è§†é¢‘ (æ ¸å¿ƒä¼˜åŒ–)
        
        è°ƒç”¨ FFmpeg ç”Ÿæˆä½åˆ†è¾¨ç‡è½»é‡è§†é¢‘ç”¨äºåç»­åˆ†æã€‚
        
        è½»é‡è§†é¢‘å‚æ•°:
            - crop: åªä¿ç•™ PPT åŒºåŸŸ
            - scale: å®½ç¼©æ”¾åˆ° 640px
            - fps: é™å¸§åˆ° 5 FPS
            - audio: å»é™¤éŸ³é¢‘
        
        Args:
            source_video: åŸå§‹è§†é¢‘è·¯å¾„
            crop_bbox: è£å‰ªåŒºåŸŸ (x, y, w, h)
        
        Returns:
            Path: è½»é‡è§†é¢‘è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        lightweight_path = self.temp_video_dir / f"{self.output_guid}_lightweight.mp4"
        
        def progress_callback(percent: int, message: str) -> None:
            """è½»é‡è§†é¢‘ç”Ÿæˆè¿›åº¦å›è°ƒ (å  10-25%)"""
            actual_progress = 10 + int(percent * 0.15)
            update_task_progress(self.output_guid, actual_progress, message)
        
        result = generate_lightweight_video(
            source_video=source_video,
            output_path=lightweight_path,
            crop_box=crop_bbox,
            target_width=640,
            target_fps=5,
            progress_callback=progress_callback
        )
        
        return result

    def _run_funnel_analysis(self, lightweight_video: Path) -> list[float]:
        """
        ä¸‰å±‚æ¼æ–—åˆ†æ (è¿è¡Œåœ¨è½»é‡è§†é¢‘ä¸Š)
        
        åœ¨è½»é‡è§†é¢‘ä¸Šæ‰§è¡Œ L1+L2+L3 åˆ†æï¼Œè¾“å‡ºæœ€ç»ˆæ—¶é—´æˆ³åˆ—è¡¨ã€‚
        
        å¤„ç†æµç¨‹:
            L1 (ç‰©ç†å±‚): GPU å¸§å·®æ£€æµ‹ â†’ åœºæ™¯åˆ†å‰²
            L2 (è´¨é‡å±‚): æ‹‰æ™®æ‹‰æ–¯æ¸…æ™°åº¦ â†’ é€‰å† å†›å¸§
            L3 (è¯­ä¹‰å±‚): OCR æ–‡æœ¬è¯†åˆ« â†’ è¿‡æ»¤é‡å¤é¡µ + éPPTé¡µé¢
        
        å…³é”®è®¾è®¡:
            - æ‰€æœ‰é€»è¾‘åŸºäºæ—¶é—´æˆ³ (ç§’ float)
            - ä½¿ç”¨è½»é‡è§†é¢‘è¿›è¡Œ OCR (å¿«é€Ÿ)
            - æ— æ–‡å­—å†…å®¹çš„å¸§è§†ä¸ºé PPT é¡µé¢ï¼Œè‡ªåŠ¨è¿‡æ»¤
        
        Args:
            lightweight_video: è½»é‡è§†é¢‘è·¯å¾„ (640px, 5fps)
        
        Returns:
            list[float]: æœ€ç»ˆæ—¶é—´æˆ³åˆ—è¡¨ï¼Œå¦‚ [1.2, 15.6, 48.2, ...]
        """
        logger.info("ğŸ”„ å¼€å§‹ä¸‰å±‚æ¼æ–—åˆ†æ...")
        logger.info("   L1: GPU å¸§å·®æ£€æµ‹ â†’ åœºæ™¯åˆ†å‰²")
        logger.info("   L2: æ‹‰æ™®æ‹‰æ–¯æ¸…æ™°åº¦ â†’ é€‰å† å†›å¸§")
        logger.info("   L3: OCR è¯†åˆ« â†’ è¿‡æ»¤é‡å¤é¡µ + éPPTé¡µé¢")
        
        # é‡ç½® OCR å»é‡å™¨
        self.ocr_deduper.reset()
        
        final_timestamps: list[float] = []
        candidate_count = 0
        
        # ----- L1 + L2: GPU å¸§å·® + æ¸…æ™°åº¦æ‹©ä¼˜ -----
        def l1l2_progress(percent: int, message: str) -> None:
            """L1+L2 è¿›åº¦å›è°ƒ (å  25-50%)"""
            actual_progress = 25 + int(percent * 0.25)
            update_task_progress(self.output_guid, actual_progress, message)
        
        for best_shot in self.frame_processor.extract_best_shots(
            lightweight_video, 
            progress_callback=l1l2_progress
        ):
            candidate_count += 1
            
            logger.debug(f"   ğŸ¬ å€™é€‰å¸§ #{candidate_count}: "
                        f"timestamp={best_shot.timestamp:.2f}s, "
                        f"æ¸…æ™°åº¦={best_shot.sharpness_score:.4f}")
            
            # ----- L3: OCR è¯†åˆ«ä¸è¿‡æ»¤ -----
            update_task_progress(
                self.output_guid, 
                50 + int((candidate_count / max(candidate_count, 1)) * 20),
                f"L3 OCR åˆ†æ: ç¬¬ {candidate_count} ä¸ªå€™é€‰"
            )
            
            # ä»è½»é‡è§†é¢‘è¯»å–å¸§è¿›è¡Œ OCR (è½»é‡è§†é¢‘è¶³å¤Ÿè¿›è¡Œæ–‡å­—è¯†åˆ«)
            frame = self.frame_processor.get_frame_at_timestamp(
                lightweight_video, 
                best_shot.timestamp
            )
            
            if frame is None:
                logger.warning(f"   âš ï¸ æ— æ³•è¯»å–å¸§ @ {best_shot.timestamp:.2f}s")
                continue
            
            is_duplicate, text = self.ocr_deduper.is_duplicate(frame)
            
            # è¿‡æ»¤æ¡ä»¶ 1: æ— æ–‡å­—å†…å®¹ â†’ é PPT é¡µé¢
            if not text or not text.strip():
                logger.debug(f"   ğŸ“„ @ {best_shot.timestamp:.2f}s æ— æ–‡å­—å†…å®¹ï¼Œåˆ¤å®šä¸ºéPPTé¡µé¢ï¼Œè·³è¿‡")
                continue
            
            # è¿‡æ»¤æ¡ä»¶ 2: ä¸å·²ä¿å­˜é¡µé¢é‡å¤
            if is_duplicate:
                logger.debug(f"   ğŸ”„ @ {best_shot.timestamp:.2f}s ä¸å·²ä¿å­˜é¡µç›¸ä¼¼åº¦è¿‡é«˜ï¼Œè·³è¿‡")
                continue
            
            # ä¿ç•™è¯¥æ—¶é—´æˆ³
            final_timestamps.append(best_shot.timestamp)
            self.ocr_deduper.mark_as_saved(text)
            
            logger.info(f"   âœ… ä¿ç•™: @ {best_shot.timestamp:.2f}s (ç¬¬ {len(final_timestamps)} é¡µ)")
        
        logger.success(f"âœ… æ¼æ–—åˆ†æå®Œæˆ: {candidate_count} å€™é€‰ â†’ {len(final_timestamps)} ä¿ç•™")
        return final_timestamps

    def _high_res_capture(
        self, 
        source_video: Path,
        timestamps: list[float],
        crop_bbox: Tuple[int, int, int, int]
    ) -> Optional[Path]:
        """
        é«˜æ¸…å›æº¯: ä»åŸè§†é¢‘æˆªå–æœ€ç»ˆç”»é¢å¹¶ç”Ÿæˆ PPTX
        
        éå†æ—¶é—´æˆ³åˆ—è¡¨ï¼Œä½¿ç”¨ FFmpeg ä»åŸè§†é¢‘ç²¾ç¡®æˆªå–é«˜æ¸…å¸§ï¼Œ
        ç„¶åç»„è£…æˆ PPTX æ–‡ä»¶ã€‚
        
        å…³é”®è®¾è®¡:
            - ä»åŸè§†é¢‘æˆªå– (ä¿ç•™å®Œæ•´åˆ†è¾¨ç‡)
            - ä½¿ç”¨åŸå§‹ bbox åæ ‡è£å‰ª
            - ä¸ç¼©æ”¾ï¼Œä¿æŒæœ€é«˜ç”»è´¨
        
        Args:
            source_video: åŸå§‹è§†é¢‘è·¯å¾„
            timestamps: æœ€ç»ˆæ—¶é—´æˆ³åˆ—è¡¨ (ç§’)
            crop_bbox: è£å‰ªåŒºåŸŸ (x, y, w, h)
        
        Returns:
            Path: ç”Ÿæˆçš„ PPTX æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        if not timestamps:
            logger.warning("âš ï¸ æ—¶é—´æˆ³åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆ PPT")
            return None
        
        logger.info(f"ğŸ“¸ å¼€å§‹é«˜æ¸…å›æº¯: å…± {len(timestamps)} ä¸ªæ—¶é—´ç‚¹")
        
        # ----- æ‰¹é‡æˆªå–é«˜æ¸…å¸§ -----
        def capture_progress(percent: int, message: str) -> None:
            """æˆªå–è¿›åº¦å›è°ƒ (å  70-90%)"""
            actual_progress = 70 + int(percent * 0.2)
            update_task_progress(self.output_guid, actual_progress, message)
        
        frame_paths = extract_frames_batch(
            source_video=source_video,
            timestamps=timestamps,
            output_dir=self.ppt_images_dir,
            crop_box=None,  # ä¸è£å‰ªï¼Œä¿ç•™å®Œæ•´åŸè§†é¢‘ç”»é¢
            progress_callback=capture_progress
        )
        
        if not frame_paths:
            logger.warning("âš ï¸ æœªèƒ½æˆªå–ä»»ä½•å¸§")
            return None
        
        # ----- ç»„è£… PPTX -----
        update_task_progress(self.output_guid, 92, "æ­£åœ¨ç”Ÿæˆ PPTX...")
        logger.info(f"ğŸ“„ ç»„è£… PPTX: {len(frame_paths)} é¡µ")
        
        ppt_path = self.ppt_output_dir / f"{self.output_guid}.pptx"
        prs = Presentation()
        prs.slide_width = Inches(16)
        prs.slide_height = Inches(9)
        
        for i, img_path in enumerate(frame_paths):
            # æ·»åŠ ç©ºç™½å¹»ç¯ç‰‡
            slide = prs.slides.add_slide(prs.slide_layouts[6])
            
            # æ·»åŠ å›¾ç‰‡ (å…¨å±)
            slide.shapes.add_picture(
                str(img_path),
                Inches(0), 
                Inches(0),
                width=prs.slide_width,
                height=prs.slide_height
            )
            
            logger.debug(f"   ğŸ“„ æ·»åŠ ç¬¬ {i+1} é¡µ: {img_path.name}")
        
        prs.save(str(ppt_path))
        logger.success(f"âœ… PPTX ç”Ÿæˆå®Œæˆ: {ppt_path.name} ({len(frame_paths)} é¡µ)")
        
        return ppt_path
