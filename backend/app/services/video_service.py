"""
æ–‡ä»¶å: video_service.py
åŠŸèƒ½æè¿°: è§†é¢‘å¤„ç†æ ¸å¿ƒæœåŠ¡ï¼Œå®ç° GPU åŠ é€Ÿçš„ PPT æå–ä¸éŸ³é¢‘è½¬å½•ç¼–æ’
æ ¸å¿ƒé€»è¾‘:
    - _locate_ppt_region(): ä½¿ç”¨ Canny è¾¹ç¼˜æ£€æµ‹å®šä½è§†é¢‘ä¸­çš„ PPT åŒºåŸŸ
    - _crop_video_ffmpeg(): FFmpeg NVENC ç¡¬ä»¶åŠ é€Ÿè£å‰ªè§†é¢‘
    - _extract_ppt_gpu_pipeline(): ä¸‰å±‚æ¼æ–— PPT æå– (L1å¸§å·® + L2æ¸…æ™°åº¦ + L3 OCRå»é‡)
    - process(): ä¸»å…¥å£ï¼Œç¼–æ’ PPT æå–ä¸éŸ³é¢‘è½¬å½•ä¸¤ä¸ªç‹¬ç«‹æ¨¡å—

å…¨é“¾è·¯æ¶æ„:
    1. FFmpeg NVENC ç¡¬ä»¶åŠ é€Ÿè£å‰ª
    2. ä¸‰å±‚æ¼æ–—æ¨¡å‹ PPT æå–:
       - L1 ç‰©ç†å±‚: GPU å¸§å·®æ£€æµ‹ (åœºæ™¯åˆ†å‰²)
       - L2 è´¨é‡å±‚: æ‹‰æ™®æ‹‰æ–¯æ¸…æ™°åº¦æ‹©ä¼˜ (é€‰å† å†›å¸§)
       - L3 è¯­ä¹‰å±‚: OCR æ–‡æœ¬å»é‡ (è¿‡æ»¤é‡å¤é¡µ)

è®¾è®¡äº®ç‚¹:
    - è£å‰ªè§†é¢‘ç”¨äºå¸§åˆ†æ (èšç„¦ PPT åŒºåŸŸï¼Œæ’é™¤å¹²æ‰°)
    - ä»åŸå§‹è§†é¢‘æˆªå–æœ€ç»ˆç”»é¢ (ä¿ç•™å®Œæ•´è´¨é‡å’Œè¾¹ç•Œ)
"""
import cv2
import shutil
import subprocess
from pathlib import Path

from pptx import Presentation
from pptx.util import Inches
from loguru import logger

from app.core.config import OUTPUT_DIR, TEMP_DIR
from app.core.task_manager import update_task_progress
from app.services.audio_service import get_audio_transcriber
from app.services.gpu_frame_processor import GPUFrameProcessor, BestShot
from app.services.ocr_deduper import OCRDeduper


class VideoService:
    """
    è§†é¢‘å¤„ç†æœåŠ¡ä¸»ç±»
    
    èŒè´£: ç¼–æ’æ•´ä¸ªè§†é¢‘ -> PPT è½¬æ¢æµç¨‹ï¼Œåè°ƒå„å­æ¨¡å—å·¥ä½œ
    
    Attributes:
        output_guid: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºç»„ç»‡è¾“å‡ºç›®å½•
        base_output_path: ä»»åŠ¡è¾“å‡ºæ ¹ç›®å½•
        frame_processor: GPU å¸§å¤„ç†å™¨ (L1 + L2)
        ocr_deduper: OCR è¯­ä¹‰å»é‡å™¨ (L3)
    
    Example:
        >>> service = VideoService(output_guid="task-123")
        >>> result = service.process(Path("lecture.mp4"), enable_ppt_extraction=True)
        >>> print(result["ppt_file"])
    """
    
    def __init__(self, output_guid: str) -> None:
        """
        åˆå§‹åŒ–è§†é¢‘å¤„ç†æœåŠ¡
        
        Args:
            output_guid: ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦ (é€šå¸¸ä¸º UUID)
        """
        self.output_guid = output_guid
        self.base_output_path = OUTPUT_DIR / output_guid
        
        # å®šä¹‰å­ç›®å½•ç»“æ„
        self.cropped_dir = self.base_output_path / "cropped_video"
        self.debug_images_dir = self.base_output_path / "debug_images"
        self.ppt_images_dir = self.base_output_path / "ppt_images"
        self.ppt_output_dir = self.base_output_path / "ppt_output"
        self.transcripts_dir = self.base_output_path / "transcripts"
        
        # åˆ›å»ºæ‰€éœ€æ–‡ä»¶å¤¹
        for p in [self.cropped_dir, self.debug_images_dir, 
                  self.ppt_images_dir, self.ppt_output_dir, self.transcripts_dir]:
            p.mkdir(parents=True, exist_ok=True)
        
        logger.debug(f"ğŸ“ è¾“å‡ºç›®å½•å·²åˆ›å»º: {self.base_output_path}")
        
        # ========== åˆå§‹åŒ– GPU å¤„ç†å™¨ (L1 + L2) ==========
        # å‚æ•°è¯´æ˜:
        #   diff_threshold: å¸§é—´å·®å¼‚é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è§†ä¸ºåœºæ™¯åˆ‡æ¢
        #   min_scene_duration: åœºæ™¯æœ€çŸ­æŒç»­æ—¶é—´ï¼Œè¿‡æ»¤åŠ¨æ€è§†é¢‘ç‰‡æ®µ
        #   sample_fps: é‡‡æ ·å¸§ç‡ï¼Œé™ä½å¯èŠ‚çœç®—åŠ›
        self.frame_processor = GPUFrameProcessor(
            diff_threshold=0.12,
            min_scene_duration=1.5,
            sample_fps=4
        )
        
        # ========== åˆå§‹åŒ– OCR å»é‡å™¨ (L3) ==========
        # å‚æ•°è¯´æ˜:
        #   similarity_threshold: æ–‡æœ¬ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶…è¿‡åˆ™åˆ¤å®šä¸ºé‡å¤é¡µ
        self.ocr_deduper = OCRDeduper(
            similarity_threshold=0.90
        )

    def process(
        self, 
        input_video_path: Path, 
        enable_ppt_extraction: bool = True,
        enable_audio_transcription: bool = True
    ) -> dict:
        """
        è§†é¢‘å¤„ç†ä¸»å…¥å£: ç¼–æ’ PPT æå–ä¸éŸ³é¢‘è½¬å½•ä¸¤ä¸ªç‹¬ç«‹æ¨¡å—
        
        ä¸¤ä¸ªåŠŸèƒ½æ¨¡å—å®Œå…¨è§£è€¦ï¼Œå¯ç‹¬ç«‹å¯ç”¨æˆ–åŒæ—¶å¯ç”¨ã€‚
        è¿›åº¦æ¡ä¼šæ ¹æ®å¯ç”¨çš„æ¨¡å—æ•°é‡è‡ªåŠ¨åˆ†é…åŒºé—´ã€‚
        
        Args:
            input_video_path: åŸå§‹è§†é¢‘æ–‡ä»¶è·¯å¾„
            enable_ppt_extraction: æ˜¯å¦æ‰§è¡Œ PPT æå–æµç¨‹ (é»˜è®¤ True)
            enable_audio_transcription: æ˜¯å¦æ‰§è¡ŒéŸ³é¢‘è½¬å½•æµç¨‹ (é»˜è®¤ False)
            
        Returns:
            dict: å¤„ç†ç»“æœï¼ŒåŒ…å«å„è¾“å‡ºæ–‡ä»¶è·¯å¾„
                - guid: ä»»åŠ¡ ID
                - cropped_video: è£å‰ªåè§†é¢‘è·¯å¾„ (å¦‚å¯ç”¨ PPT æå–)
                - ppt_file: PPT æ–‡ä»¶è·¯å¾„ (å¦‚å¯ç”¨ PPT æå–)
                - transcript_file: è½¬å½•æ–‡ä»¶è·¯å¾„ (å¦‚å¯ç”¨éŸ³é¢‘è½¬å½•)
        
        Raises:
            ValueError: PPT åŒºåŸŸå®šä½å¤±è´¥æˆ–è§†é¢‘è£å‰ªå¤±è´¥
        """
        input_video_path = Path(input_video_path)
        
        logger.info("=" * 50)
        logger.info(f"ğŸ¬ VideoService.process() å¼€å§‹å¤„ç†")
        logger.info(f"   ğŸ“‚ è¾“å…¥: {input_video_path.name}")
        logger.info(f"   ğŸ†” GUID: {self.output_guid}")
        logger.info(f"   ğŸ“Š PPTæå–: {enable_ppt_extraction} | ğŸ¤ éŸ³é¢‘è½¬å½•: {enable_audio_transcription}")
        logger.info("=" * 50)
        
        ppt_path = None
        transcript_path = None
        
        # ============================================================
        #               æ¨¡å— 1: PPT æå– (æ¡ä»¶æ‰§è¡Œ)
        # ============================================================
        if enable_ppt_extraction:
            logger.info("ğŸ“Š [PPT æå–æ¨¡å—] å¼€å§‹æ‰§è¡Œ...")
            
            # è¿›åº¦åŒºé—´åˆ†é…:
            #   - è‹¥åŒæ—¶å¯ç”¨éŸ³é¢‘: PPT å  0-85%, éŸ³é¢‘å  85-100%
            #   - è‹¥ä»… PPT: PPT å  0-100%
            ppt_progress_end = 85 if enable_audio_transcription else 100
            
            # ----- Step 1.1: å®šä½ PPT åŒºåŸŸ -----
            update_task_progress(self.output_guid, 5, "æ­£åœ¨å®šä½ PPT åŒºåŸŸ...")
            logger.info("ğŸ” Step 1.1: å®šä½ PPT åŒºåŸŸ (Canny è¾¹ç¼˜æ£€æµ‹)")
            
            bbox = self._locate_ppt_region(input_video_path)
            
            if not bbox:
                logger.error("âŒ æ— æ³•å®šä½ PPT åŒºåŸŸ")
                raise ValueError("æ— æ³•å®šä½ PPT åŒºåŸŸï¼Œè¯·ç¡®ä¿è§†é¢‘ä¸­åŒ…å«æ¸…æ™°çš„ PPT ç”»é¢")
            
            logger.success(f"âœ… PPT åŒºåŸŸå®šä½æˆåŠŸ: x={bbox[0]}, y={bbox[1]}, w={bbox[2]}, h={bbox[3]}")
            
            # ----- Step 1.2: FFmpeg ç¡¬ä»¶åŠ é€Ÿè£å‰ª -----
            update_task_progress(self.output_guid, 10, "æ­£åœ¨è£å‰ªè§†é¢‘ (GPU åŠ é€Ÿ)...")
            logger.info("âœ‚ï¸ Step 1.2: FFmpeg NVENC ç¡¬ä»¶åŠ é€Ÿè£å‰ª")
            
            cropped_video_path = self._crop_video_ffmpeg(input_video_path, bbox)
            
            if not cropped_video_path:
                logger.error("âŒ è§†é¢‘è£å‰ªå¤±è´¥")
                raise ValueError("è§†é¢‘è£å‰ªå¤±è´¥")
            
            logger.success(f"âœ… è§†é¢‘è£å‰ªå®Œæˆ: {cropped_video_path.name}")
            
            # ----- Step 1.3: ä¸‰å±‚æ¼æ–— PPT æå– -----
            logger.info("ğŸ¯ Step 1.3: ä¸‰å±‚æ¼æ–— PPT æå– (L1â†’L2â†’L3)")
            
            ppt_path = self._extract_ppt_gpu_pipeline(
                cropped_video=cropped_video_path,
                original_video=input_video_path,
                crop_bbox=bbox
            )
            
            if ppt_path:
                logger.success(f"âœ… PPT æå–å®Œæˆ: {ppt_path.name}")
            else:
                logger.warning("âš ï¸ PPT æå–å®Œæˆä½†æœªç”Ÿæˆæ–‡ä»¶")
        
        # ============================================================
        #               æ¨¡å— 2: éŸ³é¢‘è½¬å½• (æ¡ä»¶æ‰§è¡Œï¼Œå®Œå…¨ç‹¬ç«‹)
        # ============================================================
        if enable_audio_transcription:
            logger.info("ğŸ¤ [éŸ³é¢‘è½¬å½•æ¨¡å—] å¼€å§‹æ‰§è¡Œ...")
            
            # è¿›åº¦åŒºé—´:
            #   - è‹¥åŒæ—¶å¯ç”¨ PPT: ä» 85% å¼€å§‹
            #   - è‹¥ä»…éŸ³é¢‘: ä» 0% å¼€å§‹
            audio_progress_start = 85 if enable_ppt_extraction else 0
            
            update_task_progress(
                self.output_guid, 
                audio_progress_start + 5, 
                "æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ« (FunASR)..."
            )
            
            try:
                logger.info("ğŸ”Š è°ƒç”¨ FunASR è¿›è¡Œæœ¬åœ°è¯­éŸ³è¯†åˆ«...")
                transcript_text = get_audio_transcriber().transcribe_video(input_video_path)
                
                if transcript_text:
                    transcript_path = self.transcripts_dir / f"{self.output_guid}.txt"
                    with open(transcript_path, "w", encoding="utf-8") as f:
                        f.write(transcript_text)
                    logger.success(f"âœ… è½¬å½•æ–‡ä»¶å·²ä¿å­˜: {transcript_path.name}")
                    logger.debug(f"   ğŸ“ è½¬å½•å†…å®¹é¢„è§ˆ: {transcript_text[:100]}...")
                else:
                    logger.warning("âš ï¸ è½¬å½•ç»“æœä¸ºç©º")
                    
            except Exception as e:
                logger.exception(f"âŒ éŸ³é¢‘è½¬å½•è¿‡ç¨‹å‡ºé”™: {e}")
        
        # ========== è¿”å›ç»“æœ ==========
        result = {
            "guid": self.output_guid,
            "cropped_video": str(self.cropped_dir / f"{self.output_guid}_cropped.mp4") if enable_ppt_extraction else None,
            "ppt_file": str(ppt_path) if ppt_path else None,
            "transcript_file": str(transcript_path) if transcript_path else None
        }
        
        logger.info("=" * 50)
        logger.info(f"ğŸ VideoService.process() å¤„ç†å®Œæˆ")
        logger.info(f"   ğŸ“„ PPT: {'âœ… ' + ppt_path.name if ppt_path else 'âŒ æœªç”Ÿæˆ'}")
        logger.info(f"   ğŸ“ è½¬å½•: {'âœ… ' + transcript_path.name if transcript_path else 'âŒ æœªç”Ÿæˆ'}")
        logger.info("=" * 50)
        
        return result

    def _locate_ppt_region(self, video_path: Path) -> tuple | None:
        """
        å®šä½è§†é¢‘ä¸­çš„ PPT åŒºåŸŸ (è¾¹ç¼˜æ£€æµ‹æ³•)
        
        ç®—æ³•ç­–ç•¥:
            1. åœ¨è§†é¢‘ 20%/40%/60% ä½ç½®å„é‡‡æ ·ä¸€å¸§
            2. ä½¿ç”¨ Canny è¾¹ç¼˜æ£€æµ‹è¯†åˆ«è¾¹ç¼˜
            3. ä½¿ç”¨è½®å»“åˆ†æå¯»æ‰¾æœ€å¤§å››è¾¹å½¢åŒºåŸŸ
            4. è¿”å›è¯¥åŒºåŸŸçš„ bounding box
        
        Why å¤šç‚¹é‡‡æ ·?
            - è§†é¢‘å¼€å¤´/ç»“å°¾å¯èƒ½æ²¡æœ‰ PPT ç”»é¢
            - å¤šç‚¹é‡‡æ ·æé«˜æ£€æµ‹æˆåŠŸç‡
        
        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            
        Returns:
            tuple: (x, y, w, h) PPT åŒºåŸŸåæ ‡å’Œå°ºå¯¸ï¼Œå¤±è´¥è¿”å› None
        """
        logger.debug(f"ğŸ” å¼€å§‹å®šä½ PPT åŒºåŸŸ: {video_path.name}")
        
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            logger.error(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return None
        
        try:
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            sample_points = [0.2, 0.4, 0.6]  # é‡‡æ ·ç‚¹: 20%, 40%, 60%
            
            logger.debug(f"   ğŸ“Š æ€»å¸§æ•°: {total_frames}, é‡‡æ ·ç‚¹: {sample_points}")
            
            for point in sample_points:
                frame_idx = int(total_frames * point)
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                
                if not ret:
                    logger.warning(f"   âš ï¸ é‡‡æ ·ç‚¹ {point:.0%} è¯»å–å¤±è´¥")
                    continue
                
                logger.debug(f"   ğŸ–¼ï¸ åˆ†æé‡‡æ ·ç‚¹ {point:.0%} (å¸§ {frame_idx})")
                
                # ä¿å­˜è°ƒè¯•å›¾åƒ (å¯è§†åŒ–è¾¹ç¼˜æ£€æµ‹è¿‡ç¨‹)
                cv2.imwrite(str(self.debug_images_dir / "0_original.jpg"), frame)
                
                # ----- Canny è¾¹ç¼˜æ£€æµ‹æµæ°´çº¿ -----
                # Step 1: BGR -> Gray (å‡å°‘è®¡ç®—é‡)
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                cv2.imwrite(str(self.debug_images_dir / "1_gray.jpg"), gray)
                
                # Step 2: é«˜æ–¯æ¨¡ç³Š (å»å™ªï¼Œå¹³æ»‘è¾¹ç¼˜)
                blurred = cv2.GaussianBlur(gray, (5, 5), 0)
                
                # Step 3: Canny è¾¹ç¼˜æ£€æµ‹
                # Why (30, 120)? ä½é˜ˆå€¼ 30 æ£€æµ‹å¼±è¾¹ç¼˜ï¼Œé«˜é˜ˆå€¼ 120 è¿‡æ»¤å™ªç‚¹
                edged = cv2.Canny(blurred, 30, 120)
                cv2.imwrite(str(self.debug_images_dir / "2_edged.jpg"), edged)
                
                # ----- è½®å»“åˆ†æ -----
                contours, _ = cv2.findContours(
                    edged.copy(), 
                    cv2.RETR_EXTERNAL,      # åªæ£€æµ‹å¤–è½®å»“
                    cv2.CHAIN_APPROX_SIMPLE  # å‹ç¼©è½®å»“ç‚¹
                )
                
                if not contours:
                    logger.debug(f"   âš ï¸ é‡‡æ ·ç‚¹ {point:.0%} æœªæ‰¾åˆ°è½®å»“")
                    continue
                
                # å–é¢ç§¯æœ€å¤§çš„ 5 ä¸ªè½®å»“ (PPT é€šå¸¸æ˜¯æœ€å¤§çš„çŸ©å½¢åŒºåŸŸ)
                contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]
                
                for c in contours:
                    # è½®å»“è¿‘ä¼¼: å‡å°‘é¡¶ç‚¹æ•°é‡
                    peri = cv2.arcLength(c, True)
                    approx = cv2.approxPolyDP(c, 0.03 * peri, True)
                    
                    # ç­›é€‰æ¡ä»¶:
                    #   1. å¿…é¡»æ˜¯ 4 è¾¹å½¢ (PPT æ˜¯çŸ©å½¢)
                    #   2. é¢ç§¯å æ¯” > 10% (è¿‡æ»¤å°åŒºåŸŸ)
                    frame_area = frame.shape[0] * frame.shape[1]
                    area_ratio = cv2.contourArea(c) / frame_area
                    
                    if len(approx) == 4 and area_ratio > 0.1:
                        # ä¿å­˜è°ƒè¯•ç»“æœ
                        debug_img = frame.copy()
                        cv2.drawContours(debug_img, [approx], -1, (0, 255, 0), 3)
                        cv2.imwrite(str(self.debug_images_dir / "3_final_region.jpg"), debug_img)
                        
                        bbox = cv2.boundingRect(approx)
                        logger.info(f"   âœ… åœ¨é‡‡æ ·ç‚¹ {point:.0%} æ‰¾åˆ° PPT åŒºåŸŸ")
                        logger.info(f"      ğŸ“ Bounding Box: x={bbox[0]}, y={bbox[1]}, w={bbox[2]}, h={bbox[3]}")
                        logger.info(f"      ğŸ“Š é¢ç§¯å æ¯”: {area_ratio:.1%}")
                        return bbox
            
            logger.error("âŒ æ‰€æœ‰é‡‡æ ·ç‚¹å‡æœªæ‰¾åˆ°æœ‰æ•ˆ PPT åŒºåŸŸ")
            return None
            
        finally:
            cap.release()

    def _crop_video_ffmpeg(self, input_path: Path, bbox: tuple) -> Path | None:
        """
        ä½¿ç”¨ FFmpeg NVENC ç¡¬ä»¶åŠ é€Ÿè£å‰ªè§†é¢‘
        
        æ ¸å¿ƒä¼˜åŠ¿:
            - GPU è§£ç  + GPU ç¼–ç ï¼Œæ¯” OpenCV CPU å¿« 5-10 å€
            - è¾“å‡ºè´¨é‡å¯æ§ (CQ æ¨¡å¼)
        
        NVENC å…¼å®¹æ€§å¤„ç†:
            - bbox å®½é«˜å¿…é¡»å¯¹é½åˆ°å¶æ•° (NVENC ç¡¬æ€§è¦æ±‚)
            - å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ° CPU è£å‰ª
        
        Args:
            input_path: è¾“å…¥è§†é¢‘è·¯å¾„
            bbox: è£å‰ªåŒºåŸŸ (x, y, w, h)
            
        Returns:
            Path: è£å‰ªåè§†é¢‘è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        x, y, w, h = bbox
        
        # ========== NVENC å…¼å®¹æ€§ä¿®æ­£ ==========
        # Why å¯¹é½åˆ°å¶æ•°?
        #   NVENC ç¼–ç å™¨è¦æ±‚è¾“å…¥åˆ†è¾¨ç‡ä¸ºå¶æ•°ï¼Œå¦åˆ™ä¼šè§¦å‘ ACCESS_VIOLATION (0xC0000005)
        # ç­–ç•¥: å‘ä¸‹å–å¶ï¼Œç¡®ä¿ä¸å‡ºç•Œ
        original_bbox = (x, y, w, h)
        
        # ========== NVENC å…¼å®¹æ€§ä¿®æ­£ ==========
        # Why å¯¹é½åˆ° 16?
        #   NVENC ç¡¬ä»¶ç¼–ç å™¨å¯¹è¾“å…¥åˆ†è¾¨ç‡æœ‰ stride (æ­¥å¹…) è¦æ±‚ã€‚
        #   è‹¥å®½åº¦ä¸æ˜¯ 16 æˆ– 32 çš„å€æ•°ï¼Œå¯èƒ½å¯¼è‡´å†…å­˜è®¿é—®è¶Šç•Œ (ACCESS_VIOLATION 0xC0000005)ã€‚
        #   è™½ç„¶ yuv420p åªè¦æ±‚å¶æ•°ï¼Œä½†è¿™åœ¨æŸäº›é©±åŠ¨ç‰ˆæœ¬ä¸Šä¸å¤Ÿå®‰å…¨ã€‚
        x = (x // 2) * 2
        y = (y // 2) * 2
        w = (w // 16) * 16
        h = (h // 16) * 16
        
        # å®‰å…¨æ£€æŸ¥: é˜²æ­¢å®½åº¦é«˜åº¦å˜ä¸º 0
        w = max(2, w)
        h = max(2, h)
        
        if (x, y, w, h) != original_bbox:
            logger.debug(f"   ğŸ”§ bbox å·²ä¿®æ­£ä¸ºå¶æ•°: {original_bbox} â†’ ({x}, {y}, {w}, {h})")
        
        output_path = self.cropped_dir / f"{self.output_guid}_cropped.mp4"
        
        # ========== æ„é€  FFmpeg å‘½ä»¤ ==========
        # å‚æ•°è¯´æ˜:
        #   -y: è¦†ç›–å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
        #   -vf crop=w:h:x:y: è£å‰ªæ»¤é•œ
        #   -c:v h264_nvenc: ä½¿ç”¨ NVIDIA ç¡¬ä»¶ç¼–ç å™¨
        #   -pix_fmt yuv420p: åƒç´ æ ¼å¼ï¼Œå…¼å®¹æ€§æœ€ä½³
        #   -preset p1: æœ€å¿«é¢„è®¾ (p1=fastest, p7=slowest)
        #   -cq 23: è´¨é‡æ§åˆ¶ï¼Œç±»ä¼¼ x264 çš„ CRF (18-28 å¸¸ç”¨)
        #   -c:a copy: éŸ³é¢‘ç›´æ¥å¤åˆ¶ï¼Œä¸é‡æ–°ç¼–ç 
        cmd = [
            "ffmpeg",
            "-y",
            "-i", str(input_path),
            "-vf", f"crop={w}:{h}:{x}:{y}",
            "-c:v", "h264_nvenc",
            "-pix_fmt", "yuv420p",
            "-preset", "p1",
            "-cq", "23",
            "-c:a", "copy",
            str(output_path)
        ]
        
        logger.info(f"   ğŸ¬ FFmpeg NVENC ç¡¬ä»¶åŠ é€Ÿè£å‰ªä¸­...")
        logger.info(f"      è¾“å…¥: {input_path.name}")
        logger.info(f"      è¾“å‡º: {output_path.name}")
        logger.info(f"      è£å‰ªåŒºåŸŸ: crop={w}:{h}:{x}:{y}")
        logger.debug(f"   å®Œæ•´å‘½ä»¤: {' '.join(cmd)}")
        
        import time
        import re
        ffmpeg_start = time.time()
        
        try:
            # ========== ä½¿ç”¨ Popen å®æ—¶è¯»å– FFmpeg è¿›åº¦ ==========
            # Why Popen?
            #   subprocess.run() æ˜¯é˜»å¡å¼çš„ï¼Œåªèƒ½åœ¨æ‰§è¡Œå®Œæ¯•åè·å–è¾“å‡ºã€‚
            #   Popen å…è®¸å®æ—¶è¯»å– stderrï¼Œè§£æ FFmpeg çš„ frame=/time=/speed= è¿›åº¦ä¿¡æ¯ã€‚
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8',
                errors='replace'
            )
            
            # FFmpeg è¿›åº¦ä¿¡æ¯æ ¼å¼ç¤ºä¾‹:
            # frame=  123 fps= 45 q=28.0 size=    1024kB time=00:00:05.00 bitrate=1677.7kbits/s speed=1.50x
            progress_pattern = re.compile(
                r'frame=\s*(\d+)\s+fps=\s*([\d.]+)\s.*time=(\d+:\d+:\d+\.\d+).*speed=\s*([\d.]+)x'
            )
            
            last_log_time = time.time()
            stderr_lines = []  # æ”¶é›†æ‰€æœ‰ stderr ç”¨äºé”™è¯¯è¯Šæ–­
            
            logger.info("   ğŸ“Š FFmpeg å®æ—¶è¿›åº¦:")
            
            # å®æ—¶è¯»å– stderr (FFmpeg è¿›åº¦è¾“å‡ºåœ¨ stderr)
            for line in process.stderr:
                stderr_lines.append(line)
                
                # è§£æè¿›åº¦ä¿¡æ¯
                match = progress_pattern.search(line)
                if match:
                    frame_num = match.group(1)
                    fps = match.group(2)
                    time_pos = match.group(3)
                    speed = match.group(4)
                    
                    # é™åˆ¶æ—¥å¿—é¢‘ç‡: æ¯ 2 ç§’æœ€å¤šæ‰“å°ä¸€æ¬¡
                    current_time = time.time()
                    if current_time - last_log_time >= 2.0:
                        logger.info(f"      â±ï¸ frame={frame_num} fps={fps} time={time_pos} speed={speed}x")
                        last_log_time = current_time
            
            # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            process.wait()
            
            ffmpeg_time = time.time() - ffmpeg_start
            
            if process.returncode != 0:
                # åªæ‰“å° stderr å°¾éƒ¨ï¼Œé¿å…æ—¥å¿—è¿‡é•¿
                stderr_text = ''.join(stderr_lines)
                stderr_tail = stderr_text[-500:] if len(stderr_text) > 500 else stderr_text
                logger.error(f"âŒ FFmpeg è£å‰ªå¤±è´¥ (returncode={process.returncode}, è€—æ—¶: {ffmpeg_time:.1f}s)")
                logger.error(f"   stderr: {stderr_tail}")
                
                # å›é€€åˆ° CPU è£å‰ª
                logger.warning("âš ï¸ å°è¯•å›é€€åˆ° CPU æ¨¡å¼...")
                return self._crop_video_cpu_fallback(input_path, bbox)
            
            logger.success(f"âœ… FFmpeg NVENC è£å‰ªå®Œæˆ! è€—æ—¶: {ffmpeg_time:.1f}s")
            logger.info(f"      è¾“å‡ºæ–‡ä»¶: {output_path.name}")
            return output_path
            
        except subprocess.TimeoutExpired:
            logger.error("âŒ FFmpeg è£å‰ªè¶…æ—¶ (>5åˆ†é’Ÿ)")
            return None
        except FileNotFoundError:
            logger.error("âŒ FFmpeg æœªå®‰è£…æˆ–ä¸åœ¨ PATH ä¸­")
            logger.warning("âš ï¸ å°è¯•å›é€€åˆ° CPU æ¨¡å¼...")
            return self._crop_video_cpu_fallback(input_path, bbox)
        except Exception as e:
            logger.exception(f"âŒ FFmpeg è£å‰ªå¼‚å¸¸: {e}")
            return None

    def _crop_video_cpu_fallback(self, input_path: Path, bbox: tuple) -> Path | None:
        """
        CPU å›é€€è£å‰ª (å½“ FFmpeg NVENC ä¸å¯ç”¨æ—¶)
        
        ä½¿ç”¨ OpenCV é€å¸§è£å‰ªï¼Œé€Ÿåº¦è¾ƒæ…¢ä½†å…¼å®¹æ€§å¥½ã€‚
        
        Args:
            input_path: è¾“å…¥è§†é¢‘è·¯å¾„
            bbox: è£å‰ªåŒºåŸŸ (x, y, w, h)
            
        Returns:
            Path: è£å‰ªåè§†é¢‘è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        logger.info("ğŸŒ ä½¿ç”¨ CPU æ¨¡å¼è£å‰ªè§†é¢‘ (è¾ƒæ…¢)...")
        
        x, y, w, h = bbox
        output_path = self.cropped_dir / f"{self.output_guid}_cropped.mp4"
        
        cap = cv2.VideoCapture(str(input_path))
        if not cap.isOpened():
            logger.error(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {input_path}")
            return None
        
        try:
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            writer = cv2.VideoWriter(str(output_path), fourcc, fps, (w, h))
            
            frame_idx = 0
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                cropped = frame[y:y+h, x:x+w]
                writer.write(cropped)
                
                frame_idx += 1
                
                # æ¯ 100 å¸§æ›´æ–°ä¸€æ¬¡è¿›åº¦
                if frame_idx % 100 == 0:
                    progress = 10 + int((frame_idx / total_frames) * 20)
                    update_task_progress(
                        self.output_guid, 
                        min(30, progress), 
                        f"æ­£åœ¨è£å‰ªè§†é¢‘ (CPU): {frame_idx}/{total_frames}"
                    )
                    logger.debug(f"   âœ‚ï¸ CPU è£å‰ªè¿›åº¦: {frame_idx}/{total_frames}")
            
            writer.release()
            logger.success(f"âœ… CPU è£å‰ªå®Œæˆ: {output_path.name}")
            return output_path
            
        finally:
            cap.release()

    def _extract_ppt_gpu_pipeline(
        self,
        cropped_video: Path,
        original_video: Path,
        crop_bbox: tuple
    ) -> Path | None:
        """
        ä¸‰å±‚æ¼æ–— PPT æå–æ ¸å¿ƒæµç¨‹
        
        å…³é”®è®¾è®¡:
            - ä½¿ç”¨è£å‰ªè§†é¢‘è¿›è¡Œå¸§åˆ†æ (èšç„¦ PPT åŒºåŸŸï¼Œæ’é™¤å¹²æ‰°)
            - ä»åŸå§‹è§†é¢‘æˆªå–æœ€ç»ˆç”»é¢ (ä¿ç•™å®Œæ•´è´¨é‡å’Œè¾¹ç•Œ)
        
        ä¸‰å±‚æ¼æ–—æ¨¡å‹:
            L1 (ç‰©ç†å±‚): GPU å¸§å·®æ£€æµ‹ â†’ åœºæ™¯åˆ†å‰²
            L2 (è´¨é‡å±‚): æ‹‰æ™®æ‹‰æ–¯æ¸…æ™°åº¦ â†’ é€‰å† å†›å¸§
            L3 (è¯­ä¹‰å±‚): OCR æ–‡æœ¬å»é‡ â†’ è¿‡æ»¤é‡å¤é¡µ
        
        Args:
            cropped_video: è£å‰ªåçš„è§†é¢‘ (ç”¨äºå¸§åˆ†æ)
            original_video: åŸå§‹è§†é¢‘ (ç”¨äºæœ€ç»ˆæˆªå›¾)
            crop_bbox: è£å‰ªåŒºåŸŸ (x, y, w, h)
            
        Returns:
            Path: ç”Ÿæˆçš„ PPTX æ–‡ä»¶è·¯å¾„ï¼Œæ— æœ‰æ•ˆé¡µé¢æ—¶è¿”å› None
        """
        logger.info("ğŸ¯ ä¸‰å±‚æ¼æ–— PPT æå–å¼€å§‹...")
        logger.info("   L1: GPU å¸§å·®æ£€æµ‹ â†’ åœºæ™¯åˆ†å‰²")
        logger.info("   L2: æ‹‰æ™®æ‹‰æ–¯æ¸…æ™°åº¦ â†’ é€‰å† å†›å¸§")
        logger.info("   L3: OCR æ–‡æœ¬å»é‡ â†’ è¿‡æ»¤é‡å¤é¡µ")
        
        # åˆ›å»º PPT æ–‡æ¡£
        ppt_path = self.ppt_output_dir / f"{self.output_guid}.pptx"
        prs = Presentation()
        prs.slide_width = Inches(16)
        prs.slide_height = Inches(9)
        
        # é‡ç½® OCR å»é‡å™¨ (æ¸…é™¤ä¸Šä¸€æ¬¡ä»»åŠ¡çš„ç¼“å­˜)
        self.ocr_deduper.reset()
        
        saved_count = 0
        processed_shots = 0
        
        # ----- è¿›åº¦å›è°ƒå‡½æ•° -----
        def progress_callback(percent: int, message: str) -> None:
            """L1/L2 é˜¶æ®µè¿›åº¦æ›´æ–° (å  30-70%)"""
            actual_progress = 30 + int(percent * 0.4)
            update_task_progress(self.output_guid, actual_progress, message)
        
        try:
            # ========== L1 + L2: GPU å¸§å¤„ç† ==========
            logger.info("ğŸ”„ L1+L2: å¼€å§‹ GPU å¸§å¤„ç†...")
            
            for best_shot in self.frame_processor.extract_best_shots(
                cropped_video, 
                progress_callback=progress_callback
            ):
                processed_shots += 1
                
                logger.debug(f"   ğŸ¬ å€™é€‰å¸§ #{processed_shots}: å¸§å·={best_shot.frame_index}, "
                            f"æ¸…æ™°åº¦={best_shot.sharpness_score:.4f}")
                
                # ----- ä»åŸå§‹è§†é¢‘è¯»å–å¯¹åº”å¸§ -----
                # Why ç”¨åŸå§‹è§†é¢‘?
                #   è£å‰ªè§†é¢‘ç”¨äºåˆ†æ (æ’é™¤å¹²æ‰°)ï¼Œä½†æœ€ç»ˆæˆªå›¾è¦ä¿ç•™å®Œæ•´ç”»é¢è´¨é‡
                original_frame = self.frame_processor.get_frame_at_index(
                    original_video,
                    best_shot.frame_index
                )
                
                if original_frame is None:
                    logger.warning(f"   âš ï¸ æ— æ³•è¯»å–åŸå§‹å¸§ {best_shot.frame_index}")
                    continue
                
                # ========== L3: OCR è¯­ä¹‰å»é‡ ==========
                update_task_progress(
                    self.output_guid, 
                    70 + int((processed_shots / max(processed_shots, 1)) * 20),
                    f"OCR å»é‡æ£€æŸ¥: ç¬¬ {processed_shots} ä¸ªå€™é€‰å¸§"
                )
                
                is_duplicate, text = self.ocr_deduper.is_duplicate(original_frame)
                
                if is_duplicate:
                    logger.debug(f"   ğŸ”„ å¸§ {best_shot.frame_index} è¢« OCR å»é‡ä¸¢å¼ƒ (æ–‡æœ¬ç›¸ä¼¼åº¦è¿‡é«˜)")
                    continue
                
                # ========== ä¿å­˜åˆ° PPT ==========
                self._save_frame_to_ppt(original_frame, prs, saved_count)
                saved_count += 1
                
                # æ›´æ–° OCR ç¼“å­˜
                self.ocr_deduper.mark_as_saved(text)
                
                logger.info(f"   ğŸ“„ ä¿å­˜ PPT ç¬¬ {saved_count} é¡µ (å¸§ {best_shot.frame_index}, "
                           f"æ¸…æ™°åº¦: {best_shot.sharpness_score:.4f})")
            
            # ========== ä¿å­˜ PPT ==========
            if saved_count > 0:
                prs.save(str(ppt_path))
                logger.success(f"âœ… PPT ç”Ÿæˆå®Œæ¯•ï¼Œå…± {saved_count} é¡µ: {ppt_path.name}")
                return ppt_path
            else:
                logger.warning("âš ï¸ æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆé¡µé¢ï¼Œæ— æ³•ç”Ÿæˆ PPT")
                return None
        
        finally:
            # ========== GPU æ˜¾å­˜æ¸…ç† (æ— è®ºæˆåŠŸæˆ–å¼‚å¸¸éƒ½ä¼šæ‰§è¡Œ) ==========
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                logger.debug("ğŸ§¹ GPU æ˜¾å­˜å·²æ¸…ç† (finally block)")

    def _save_frame_to_ppt(self, frame, prs, index: int) -> None:
        """
        å°†å¸§ä¿å­˜ä¸º PPT é¡µé¢
        
        Args:
            frame: OpenCV BGR æ ¼å¼çš„å¸§æ•°æ® (numpy.ndarray)
            prs: python-pptx Presentation å¯¹è±¡
            index: é¡µé¢ç´¢å¼• (ç”¨äºæ–‡ä»¶å‘½å)
        """
        img_path = self.ppt_images_dir / f"slide_{index:04d}.jpg"
        
        # ä¿å­˜é«˜è´¨é‡ JPEG (è´¨é‡ 95%)
        cv2.imwrite(
            str(img_path), 
            frame, 
            [cv2.IMWRITE_JPEG_QUALITY, 95]
        )
        
        # æ·»åŠ åˆ° PPT (ä½¿ç”¨ç©ºç™½å¸ƒå±€)
        slide = prs.slides.add_slide(prs.slide_layouts[6])
        slide.shapes.add_picture(
            str(img_path),
            Inches(0), 
            Inches(0),
            width=prs.slide_width,
            height=prs.slide_height
        )
