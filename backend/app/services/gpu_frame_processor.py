"""
æ–‡ä»¶å: gpu_frame_processor.py
åŠŸèƒ½æè¿°: GPU åŠ é€Ÿçš„è§†é¢‘å¸§å¤„ç†æ¨¡å—ï¼Œå®ç°ä¸‰å±‚æ¼æ–—æ¨¡å‹çš„ L1 ç‰©ç†å±‚ + L2 è´¨é‡å±‚
æ ¸å¿ƒé€»è¾‘:
    - L1 ç‰©ç†å±‚: ä½¿ç”¨ PyTorch GPU è®¡ç®—å¸§é—´å·®å¼‚ (MAD ç®—æ³•)ï¼Œæ£€æµ‹åœºæ™¯åˆ‡æ¢
    - L2 è´¨é‡å±‚: ä½¿ç”¨ Laplacian Variance è¯„ä¼°æ¯å¸§æ¸…æ™°åº¦ï¼Œåœ¨åœºæ™¯ç‰‡æ®µå†…æ‹©ä¼˜é€‰å‡º"å† å†›å¸§"

è®¾è®¡äº®ç‚¹:
    - **Timestamp First**: æ‰€æœ‰é€»è¾‘åŸºäºæ—¶é—´æˆ³ (ç§’ float)ï¼Œä¸¥ç¦ä¾èµ– frame_index
    - å…¨ç¨‹ä½¿ç”¨ torch.Tensor åœ¨ GPU ä¸Šè¿ç®—ï¼Œé¿å… CPU-GPU æ•°æ®ä¼ è¾“å¼€é”€
    - æ”¯æŒ min_scene_duration è¿‡æ»¤åŠ¨æ€ç”»é¢ç‰‡æ®µ
    - Generator æ¨¡å¼æµå¼è¾“å‡ºï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜

ä¾èµ–: torch (CUDA), opencv-python
"""
import cv2
import torch
from pathlib import Path
from dataclasses import dataclass
from typing import Generator, Callable, Optional

from loguru import logger


@dataclass
class BestShot:
    """
    åœºæ™¯ç‰‡æ®µå†…çš„"å† å†›å¸§"æ•°æ®ç»“æ„ (Timestamp-First è®¾è®¡)
    
    ä¸€ä¸ª BestShot ä»£è¡¨ä¸€ä¸ªé™æ­¢åœºæ™¯ä¸­æœ€æ¸…æ™°çš„é‚£ä¸€å¸§ï¼Œ
    æ˜¯ä¸‰å±‚æ¼æ–—æ¨¡å‹ L1+L2 çš„è¾“å‡ºç»“æœã€‚
    
    æ ¸å¿ƒè®¾è®¡:
        - ä»¥ timestamp (ç§’) ä½œä¸ºä¸»é”®é”šç‚¹
        - frame_index ä»…ä¾›è°ƒè¯•å‚è€ƒï¼Œä¸åº”ç”¨äºä¸šåŠ¡é€»è¾‘
    
    Attributes:
        timestamp: å† å†›å¸§çš„æ—¶é—´æˆ³ (ç§’ï¼Œfloat)ï¼Œæ ¸å¿ƒé”šç‚¹
        frame_index: åŸå§‹è§†é¢‘ä¸­çš„å¸§å· (ä»…è°ƒè¯•ç”¨)
        sharpness_score: æ‹‰æ™®æ‹‰æ–¯æ¸…æ™°åº¦å¾—åˆ† (è¶Šé«˜è¶Šæ¸…æ™°)
        scene_start_ts: æ‰€å±åœºæ™¯çš„èµ·å§‹æ—¶é—´æˆ³ (ç§’)
        scene_end_ts: æ‰€å±åœºæ™¯çš„ç»“æŸæ—¶é—´æˆ³ (ç§’)
    """
    timestamp: float          # æ ¸å¿ƒé”šç‚¹ (ç§’)
    frame_index: int          # ä»…ä¾›è°ƒè¯•å‚è€ƒ
    sharpness_score: float
    scene_start_ts: float     # åœºæ™¯èµ·å§‹æ—¶é—´ (ç§’)
    scene_end_ts: float       # åœºæ™¯ç»“æŸæ—¶é—´ (ç§’)


class GPUFrameProcessor:
    """
    GPU åŠ é€Ÿçš„å¸§å¤„ç†å™¨
    
    ä¸‰å±‚æ¼æ–—æ¨¡å‹çš„å‰ä¸¤å±‚ (L1 ç‰©ç†å±‚ + L2 è´¨é‡å±‚) å®ç°ã€‚
    
    ç®—æ³•æµç¨‹:
        1. æŒ‰ sample_interval ç§’é‡‡æ ·è§†é¢‘å¸§
        2. L1: å®æ—¶è®¡ç®—å¸§é—´å·®å¼‚ (MAD)
        3. å½“å·®å¼‚è¶…è¿‡é˜ˆå€¼ï¼Œæ ‡è®°ä¸ºæ–°åœºæ™¯
        4. L2: å¯¹ä¸Šä¸€ä¸ªåœºæ™¯ï¼Œé€‰å‡ºæ¸…æ™°åº¦æœ€é«˜çš„å¸§ä½œä¸º"å† å†›å¸§"
        5. åœºæ™¯æŒç»­æ—¶é—´ä¸è¶³ min_scene_duration çš„ï¼Œè§†ä¸º"åŠ¨æ€ç‰‡æ®µ"ä¸¢å¼ƒ
    
    Attributes:
        diff_threshold: å¸§é—´å·®å¼‚é˜ˆå€¼
        min_scene_duration: åœºæ™¯æœ€çŸ­æŒç»­æ—¶é—´ (ç§’)
        sample_interval: é‡‡æ ·é—´éš” (ç§’)
        device: è®¡ç®—è®¾å¤‡ (cuda/cpu)
        laplacian_kernel: é¢„åŠ è½½åˆ° GPU çš„æ‹‰æ™®æ‹‰æ–¯ç®—å­
    
    Example:
        >>> processor = GPUFrameProcessor(diff_threshold=0.12)
        >>> for shot in processor.extract_best_shots(video_path):
        ...     print(f"Timestamp {shot.timestamp:.2f}s, Sharpness: {shot.sharpness_score}")
    """
    
    def __init__(
        self,
        diff_threshold: float = 0.12,
        min_scene_duration: float = 1.5,
        sample_interval: float = 0.2,
        device: str = "cuda"
    ) -> None:
        """
        åˆå§‹åŒ– GPU å¸§å¤„ç†å™¨
        
        Args:
            diff_threshold: å¸§é—´å·®å¼‚é˜ˆå€¼ (0-1)
                - è¶…è¿‡æ­¤å€¼è§†ä¸ºåœºæ™¯åˆ‡æ¢
                - è¾ƒä½å€¼ (0.08-0.12): å¯¹å¾®å°å˜åŒ–æ•æ„Ÿï¼Œé€‚åˆé™æ€ PPT
                - è¾ƒé«˜å€¼ (0.15-0.25): å¿½ç•¥å°å¹…åŠ¨ç”»ï¼Œé€‚åˆå«åŠ¨æ•ˆçš„æ¼”ç¤º
                
            min_scene_duration: åœºæ™¯æœ€çŸ­æŒç»­æ—¶é—´ (ç§’)
                - ç”¨äºè¿‡æ»¤åŠ¨æ€å†…å®¹ (å¦‚ PPT ä¸­åµŒå…¥çš„è§†é¢‘)
                - å»ºè®®å€¼ 1.0-2.0 ç§’
                
            sample_interval: é‡‡æ ·é—´éš” (ç§’)
                - æ¯éš”å¤šå°‘ç§’å–ä¸€æ¬¡æ ·
                - é»˜è®¤ 0.2 ç§’ (æ¯ç§’ 5 ä¸ªé‡‡æ ·ç‚¹)
                - è¾ƒå¤§å€¼èŠ‚çœç®—åŠ›ï¼Œä½†å¯èƒ½é”™è¿‡å¿«é€Ÿç¿»é¡µ
                
            device: è®¡ç®—è®¾å¤‡
                - "cuda": ä½¿ç”¨ GPU (æ¨è)
                - "cpu": å›é€€åˆ° CPU
        """
        self.diff_threshold = diff_threshold
        self.min_scene_duration = min_scene_duration
        self.sample_interval = sample_interval
        
        # ========== æ£€æŸ¥ CUDA å¯ç”¨æ€§ ==========
        if device == "cuda" and not torch.cuda.is_available():
            logger.warning("âš ï¸ CUDA ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU æ¨¡å¼")
            self.device = torch.device("cpu")
        else:
            self.device = torch.device(device)
            if device == "cuda":
                gpu_name = torch.cuda.get_device_name(0)
                logger.info(f"ğŸš€ GPU å¸§å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ: {gpu_name}")
        
        # ========== é¢„åŠ è½½æ‹‰æ™®æ‹‰æ–¯æ ¸åˆ° GPU ==========
        # æ ‡å‡† 3x3 æ‹‰æ™®æ‹‰æ–¯ç®—å­
        # ç”¨äºè¾¹ç¼˜æ£€æµ‹ï¼Œæ–¹å·®è¶Šå¤§è¡¨ç¤ºå›¾åƒè¶Šæ¸…æ™°
        self.laplacian_kernel = torch.tensor(
            [[0, 1, 0],
             [1, -4, 1],
             [0, 1, 0]],
            dtype=torch.float32,
            device=self.device
        ).view(1, 1, 3, 3)
        
        logger.debug(f"âš™ï¸ å‚æ•°é…ç½®: diff_threshold={diff_threshold}, "
                    f"min_scene_duration={min_scene_duration}s, sample_interval={sample_interval}s")
    
    def _frame_to_tensor(self, frame) -> torch.Tensor:
        """
        å°† OpenCV BGR å¸§è½¬æ¢ä¸º GPU ç°åº¦å¼ é‡
        
        Why ç°åº¦?
            å¸§å·®å’Œæ¸…æ™°åº¦è®¡ç®—éƒ½åªéœ€è¦äº®åº¦ä¿¡æ¯ï¼Œ
            è½¬ä¸ºç°åº¦å¯å‡å°‘ 3 å€æ•°æ®ä¼ è¾“é‡å’Œè®¡ç®—é‡ã€‚
        
        Args:
            frame: OpenCV BGR æ ¼å¼çš„å¸§ (numpy.ndarray)
            
        Returns:
            torch.Tensor: å½’ä¸€åŒ–åˆ° [0, 1] çš„ç°åº¦å¼ é‡
        """
        # BGR -> Gray (ä½¿ç”¨ OpenCVï¼Œæ¯” torch æ›´å¿«)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # numpy -> torchï¼Œå¹¶å½’ä¸€åŒ–åˆ° 0-1
        tensor = torch.from_numpy(gray).float().to(self.device) / 255.0
        return tensor
    
    def compute_frame_difference(
        self,
        frame1: torch.Tensor,
        frame2: torch.Tensor
    ) -> float:
        """
        L1 ç‰©ç†å±‚æ ¸å¿ƒ: è®¡ç®—ä¸¤å¸§ä¹‹é—´çš„å·®å¼‚åº¦
        
        ä½¿ç”¨ Mean Absolute Difference (MAD) ç®—æ³•:
            1. è®¡ç®—ä¸¤å¸§åƒç´ çº§ç»å¯¹å·®å€¼
            2. å–å‡å€¼ä½œä¸ºå·®å¼‚åˆ†æ•°
            3. è¿”å› 0-1 ä¹‹é—´çš„å·®å¼‚åˆ†æ•°
        
        Why MAD è€Œé SSIM?
            - MAD åœ¨ GPU ä¸Šè®¡ç®—æå¿« (å•æ¬¡å¼ é‡è¿ç®—)
            - å¯¹äºåœºæ™¯åˆ‡æ¢æ£€æµ‹ï¼ŒMAD çš„æ•æ„Ÿåº¦è¶³å¤Ÿ
            - SSIM è™½ç„¶æ›´ç²¾ç¡®ï¼Œä½†è®¡ç®—å¤æ‚åº¦é«˜ï¼Œä¸é€‚åˆå®æ—¶æµå¤„ç†
        
        Args:
            frame1: ç¬¬ä¸€å¸§ (torch.Tensor)
            frame2: ç¬¬äºŒå¸§ (torch.Tensor)
            
        Returns:
            float: å·®å¼‚åˆ†æ•° (0-1)ï¼Œè¶Šå¤§å·®å¼‚è¶Šå¤§
        """
        diff = torch.abs(frame1 - frame2).mean().item()
        return diff
    
    def compute_laplacian_sharpness(self, frame: torch.Tensor) -> float:
        """
        L2 è´¨é‡å±‚æ ¸å¿ƒ: è®¡ç®—å¸§çš„æ¸…æ™°åº¦å¾—åˆ† (Laplacian Variance)
        
        åŸç†:
            1. ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­å¯¹å›¾åƒè¿›è¡Œå·ç§¯ (æ£€æµ‹è¾¹ç¼˜)
            2. è®¡ç®—å·ç§¯ç»“æœçš„æ–¹å·®
            3. æ–¹å·®è¶Šå¤§ï¼Œè¯´æ˜è¾¹ç¼˜è¶Šé”åˆ©ï¼Œå›¾åƒè¶Šæ¸…æ™°
        
        Why Laplacian Variance?
            - å¯¹ç„¦è·/æ¨¡ç³Šå˜åŒ–éå¸¸æ•æ„Ÿ
            - èƒ½æœ‰æ•ˆåŒºåˆ†æ¸…æ™°å¸§å’Œè¿åŠ¨æ¨¡ç³Šå¸§
            - è®¡ç®—ç®€å•ï¼Œé€‚åˆ GPU å¹¶è¡Œ
        
        Args:
            frame: è¾“å…¥å¸§ (torch.Tensor)
            
        Returns:
            float: æ¸…æ™°åº¦å¾—åˆ† (è¶Šé«˜è¶Šæ¸…æ™°)
        """
        # æ·»åŠ  batch å’Œ channel ç»´åº¦: (H, W) -> (1, 1, H, W)
        frame_4d = frame.unsqueeze(0).unsqueeze(0)
        
        # GPU å·ç§¯è¿ç®—
        laplacian = torch.nn.functional.conv2d(
            frame_4d,
            self.laplacian_kernel,
            padding=1
        )
        
        # è¿”å›æ–¹å·®ä½œä¸ºæ¸…æ™°åº¦å¾—åˆ†
        variance = laplacian.var().item()
        return variance
    
    def extract_best_shots(
        self,
        video_path: Path,
        progress_callback: Optional[Callable[[int, str], None]] = None
    ) -> Generator[BestShot, None, None]:
        """
        ä¸»å…¥å£: ä»è§†é¢‘ä¸­æå–æ¯ä¸ªåœºæ™¯çš„"å† å†›å¸§" (Timestamp-First)
        
        ç®—æ³•æµç¨‹:
            1. æŒ‰ sample_interval ç§’é‡‡æ ·è§†é¢‘å¸§
            2. å®æ—¶è®¡ç®—å¸§é—´å·®å¼‚ (L1)
            3. å½“å·®å¼‚è¶…è¿‡é˜ˆå€¼ï¼Œæ ‡è®°ä¸ºæ–°åœºæ™¯
            4. å¯¹ä¸Šä¸€ä¸ªåœºæ™¯ï¼Œé€‰å‡ºæ¸…æ™°åº¦æœ€é«˜çš„å¸§ (L2)
            5. åœºæ™¯æŒç»­æ—¶é—´ä¸è¶³ min_scene_duration çš„ï¼Œè§†ä¸º"åŠ¨æ€ç‰‡æ®µ"ä¸¢å¼ƒ
        
        å…³é”®è®¾è®¡:
            - æ‰€æœ‰è¾“å‡ºåŸºäºæ—¶é—´æˆ³ (ç§’)ï¼Œè€Œéå¸§å·
            - ä½¿ç”¨ CAP_PROP_POS_MSEC è·å–ç²¾ç¡®æ—¶é—´æˆ³
        
        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
                - å»ºè®®ä¼ å…¥è½»é‡è§†é¢‘ä»¥åŠ é€Ÿå¤„ç†
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
                - ç­¾å: callback(percent: int, message: str)
                - ç”¨äºæ›´æ–°ä»»åŠ¡è¿›åº¦æ¡
            
        Yields:
            BestShot: æ¯ä¸ªæœ‰æ•ˆåœºæ™¯çš„å† å†›å¸§ä¿¡æ¯
        
        Note:
            ä½¿ç”¨ Generator æ¨¡å¼æ˜¯ä¸ºäº†é¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å¸§åˆ°å†…å­˜
        """
        video_path = Path(video_path)
        cap = cv2.VideoCapture(str(video_path))
        
        if not cap.isOpened():
            logger.error(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return
        
        try:
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps if fps > 0 else 0
            
            # è®¡ç®—å¸§é‡‡æ ·é—´éš” (å¸§æ•°)
            # Why ä¿ç•™å¸§é—´éš”? å› ä¸º OpenCV éœ€è¦ç”¨ frame index å®šä½
            frame_sample_interval = max(1, int(fps * self.sample_interval))
            
            logger.info(f"ğŸ¬ å¼€å§‹ GPU å¸§å¤„ç† (Timestamp-First)")
            logger.info(f"   ğŸ“Š æ€»æ—¶é•¿: {duration:.1f}s, FPS: {fps:.1f}")
            logger.info(f"   âš™ï¸ é‡‡æ ·é—´éš”: {self.sample_interval}s ({frame_sample_interval} å¸§)")
            
            # ========== åœºæ™¯çŠ¶æ€æœº ==========
            prev_tensor: Optional[torch.Tensor] = None
            scene_start_ts: float = 0.0            # å½“å‰åœºæ™¯èµ·å§‹æ—¶é—´æˆ³
            scene_best_ts: float = 0.0             # å½“å‰åœºæ™¯æœ€æ¸…æ™°å¸§æ—¶é—´æˆ³
            scene_best_frame_idx: int = 0          # å½“å‰åœºæ™¯æœ€æ¸…æ™°å¸§ç´¢å¼• (è°ƒè¯•ç”¨)
            scene_best_sharpness: float = -1.0     # å½“å‰åœºæ™¯æœ€é«˜æ¸…æ™°åº¦
            
            frame_idx = 0                          # å½“å‰è¯»å–å¸§ç´¢å¼•
            sampled_count = 0                      # å·²é‡‡æ ·å¸§æ•°
            total_scenes = 0                       # æ€»åœºæ™¯æ•° (ç”¨äºæ—¥å¿—)
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ========== è·³å¸§é‡‡æ · ==========
                if frame_idx % frame_sample_interval != 0:
                    frame_idx += 1
                    continue
                
                sampled_count += 1
                
                # ========== è·å–å½“å‰å¸§æ—¶é—´æˆ³ (ç§’) ==========
                # Why ä½¿ç”¨ CAP_PROP_POS_MSEC?
                #   æ¯” frame_idx / fps æ›´å‡†ç¡®ï¼Œå°¤å…¶å¯¹äº VFR è§†é¢‘
                current_ts = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0
                
                # è¿›åº¦å›è°ƒ (æ¯ 10 æ¬¡é‡‡æ ·æ›´æ–°ä¸€æ¬¡)
                if progress_callback and sampled_count % 10 == 0:
                    percent = int((current_ts / duration) * 100) if duration > 0 else 0
                    progress_callback(percent, f"L1+L2 åˆ†æ: {current_ts:.1f}s / {duration:.1f}s")
                
                # è½¬æ¢åˆ° GPU å¼ é‡
                current_tensor = self._frame_to_tensor(frame)
                
                # è®¡ç®—å½“å‰å¸§æ¸…æ™°åº¦ (æ— è®ºæ˜¯å¦åˆ‡æ¢åœºæ™¯éƒ½è¦ç®—ï¼Œç”¨äºæ‹©ä¼˜)
                sharpness = self.compute_laplacian_sharpness(current_tensor)
                
                # ========== é¦–å¸§åˆå§‹åŒ– ==========
                if prev_tensor is None:
                    prev_tensor = current_tensor
                    scene_best_sharpness = sharpness
                    scene_best_ts = current_ts
                    scene_best_frame_idx = frame_idx
                    frame_idx += 1
                    continue
                
                # ========== L1: è®¡ç®—å¸§é—´å·®å¼‚ ==========
                diff = self.compute_frame_difference(prev_tensor, current_tensor)
                
                # ========== æ£€æµ‹åœºæ™¯åˆ‡æ¢ ==========
                if diff > self.diff_threshold:
                    # åœºæ™¯ç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦æ»¡è¶³æœ€å°æŒç»­æ—¶é—´
                    scene_duration = current_ts - scene_start_ts
                    
                    if scene_duration >= self.min_scene_duration:
                        # æœ‰æ•ˆåœºæ™¯ï¼Œè¾“å‡ºå† å†›å¸§
                        total_scenes += 1
                        logger.debug(f"   ğŸ¯ åœºæ™¯ #{total_scenes} [{scene_start_ts:.2f}s-{current_ts:.2f}s] "
                                   f"å† å†›å¸§ @ {scene_best_ts:.2f}s, æ¸…æ™°åº¦: {scene_best_sharpness:.4f}")
                        
                        yield BestShot(
                            timestamp=scene_best_ts,
                            frame_index=scene_best_frame_idx,
                            sharpness_score=scene_best_sharpness,
                            scene_start_ts=scene_start_ts,
                            scene_end_ts=current_ts
                        )
                    else:
                        # æŒç»­æ—¶é—´ä¸è¶³ï¼Œä¸¢å¼ƒ (å¯èƒ½æ˜¯åŠ¨æ€è§†é¢‘ç‰‡æ®µ)
                        logger.debug(f"   â­ï¸ åœºæ™¯ [{scene_start_ts:.2f}s-{current_ts:.2f}s] è¢«ä¸¢å¼ƒ: "
                                   f"æŒç»­æ—¶é—´ {scene_duration:.2f}s < {self.min_scene_duration}s")
                    
                    # é‡ç½®åœºæ™¯çŠ¶æ€
                    scene_start_ts = current_ts
                    scene_best_sharpness = sharpness
                    scene_best_ts = current_ts
                    scene_best_frame_idx = frame_idx
                else:
                    # åŒä¸€åœºæ™¯å†…ï¼Œæ›´æ–°å† å†›å¸§ (å¦‚æœå½“å‰å¸§æ›´æ¸…æ™°)
                    if sharpness > scene_best_sharpness:
                        scene_best_sharpness = sharpness
                        scene_best_ts = current_ts
                        scene_best_frame_idx = frame_idx
                
                prev_tensor = current_tensor
                frame_idx += 1
            
            # ========== å¤„ç†æœ€åä¸€ä¸ªåœºæ™¯ ==========
            final_ts = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0
            scene_duration = final_ts - scene_start_ts if final_ts > scene_start_ts else duration - scene_start_ts
            
            if scene_duration >= self.min_scene_duration:
                total_scenes += 1
                logger.debug(f"   ğŸ¯ æœ€ååœºæ™¯ #{total_scenes} [{scene_start_ts:.2f}s-{final_ts:.2f}s] "
                           f"å† å†›å¸§ @ {scene_best_ts:.2f}s, æ¸…æ™°åº¦: {scene_best_sharpness:.4f}")
                
                yield BestShot(
                    timestamp=scene_best_ts,
                    frame_index=scene_best_frame_idx,
                    sharpness_score=scene_best_sharpness,
                    scene_start_ts=scene_start_ts,
                    scene_end_ts=final_ts
                )
            
            logger.success(f"âœ… GPU å¸§å¤„ç†å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {total_scenes} ä¸ªæœ‰æ•ˆåœºæ™¯")
                
        finally:
            cap.release()
            # æ¸…ç† GPU ç¼“å­˜
            if self.device.type == "cuda":
                torch.cuda.empty_cache()
                logger.debug("ğŸ§¹ GPU æ˜¾å­˜å·²æ¸…ç†")
    
    def get_frame_at_timestamp(self, video_path: Path, timestamp: float):
        """
        å·¥å…·æ–¹æ³•: ä»è§†é¢‘ä¸­è¯»å–æŒ‡å®šæ—¶é—´æˆ³çš„å¸§
        
        ç”¨äºåœ¨ç¡®å®šå† å†›å¸§æ—¶é—´æˆ³åï¼Œä»åŸå§‹è§†é¢‘ä¸­æˆªå–å®é™…ç”»é¢ã€‚
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            timestamp: ç›®æ ‡æ—¶é—´æˆ³ (ç§’)
            
        Returns:
            numpy.ndarray: BGR æ ¼å¼çš„å¸§æ•°æ®ï¼Œå¤±è´¥è¿”å› None
        """
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            logger.warning(f"âš ï¸ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return None
        
        try:
            # ä½¿ç”¨æ¯«ç§’å®šä½ (æ¯”å¸§å·å®šä½æ›´ç²¾ç¡®)
            cap.set(cv2.CAP_PROP_POS_MSEC, timestamp * 1000)
            ret, frame = cap.read()
            return frame if ret else None
        finally:
            cap.release()
    
    # ========== å…¼å®¹æ€§æ–¹æ³• (deprecated) ==========
    def get_frame_at_index(self, video_path: Path, frame_index: int):
        """
        [DEPRECATED] ä½¿ç”¨ get_frame_at_timestamp() ä»£æ›¿
        
        ä¿ç•™æ­¤æ–¹æ³•ä»…ä¸ºå‘åå…¼å®¹ï¼Œæ–°ä»£ç åº”ä½¿ç”¨æ—¶é—´æˆ³ç‰ˆæœ¬ã€‚
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            frame_index: å¸§ç´¢å¼•å· (0-indexed)
            
        Returns:
            numpy.ndarray: BGR æ ¼å¼çš„å¸§æ•°æ®ï¼Œå¤±è´¥è¿”å› None
        """
        logger.warning("âš ï¸ get_frame_at_index() å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ get_frame_at_timestamp()")
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            logger.warning(f"âš ï¸ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return None
        
        try:
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)
            ret, frame = cap.read()
            return frame if ret else None
        finally:
            cap.release()
