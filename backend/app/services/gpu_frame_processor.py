"""
æ–‡ä»¶å: gpu_frame_processor.py
åŠŸèƒ½æè¿°: GPU åŠ é€Ÿçš„è§†é¢‘å¸§å¤„ç†æ¨¡å—ï¼Œå®ç°ä¸‰å±‚æ¼æ–—æ¨¡å‹çš„ L1 ç‰©ç†å±‚ + L2 è´¨é‡å±‚
æ ¸å¿ƒé€»è¾‘:
    - L1 ç‰©ç†å±‚: ä½¿ç”¨ PyTorch GPU è®¡ç®—å¸§é—´å·®å¼‚ (MAD ç®—æ³•)ï¼Œæ£€æµ‹åœºæ™¯åˆ‡æ¢
    - L2 è´¨é‡å±‚: ä½¿ç”¨ Laplacian Variance è¯„ä¼°æ¯å¸§æ¸…æ™°åº¦ï¼Œåœ¨åœºæ™¯ç‰‡æ®µå†…æ‹©ä¼˜é€‰å‡º"å† å†›å¸§"

è®¾è®¡äº®ç‚¹:
    - å…¨ç¨‹ä½¿ç”¨ torch.Tensor åœ¨ GPU ä¸Šè¿ç®—ï¼Œé¿å… CPU-GPU æ•°æ®ä¼ è¾“å¼€é”€
    - æ”¯æŒ min_scene_duration è¿‡æ»¤æŒç»­åŠ¨æ€ç”»é¢ï¼ˆå¦‚ PPT ä¸­åµŒå…¥çš„è§†é¢‘ç‰‡æ®µï¼‰
    - Generator æ¨¡å¼æµå¼è¾“å‡ºï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜

ä¾èµ–: torch (CUDA), opencv-python
"""
import cv2
import torch
from pathlib import Path
from dataclasses import dataclass
from typing import Generator, Callable, Optional

from loguru import logger


@dataclass
class BestShot:
    """
    åœºæ™¯ç‰‡æ®µå†…çš„"å† å†›å¸§"æ•°æ®ç»“æ„
    
    ä¸€ä¸ª BestShot ä»£è¡¨ä¸€ä¸ªé™æ­¢åœºæ™¯ä¸­æœ€æ¸…æ™°çš„é‚£ä¸€å¸§ï¼Œ
    æ˜¯ä¸‰å±‚æ¼æ–—æ¨¡å‹ L1+L2 çš„è¾“å‡ºç»“æœã€‚
    
    Attributes:
        frame_index: åŸå§‹è§†é¢‘ä¸­çš„å¸§å· (0-indexed)
        sharpness_score: æ‹‰æ™®æ‹‰æ–¯æ¸…æ™°åº¦å¾—åˆ† (è¶Šé«˜è¶Šæ¸…æ™°)
        scene_start: æ‰€å±åœºæ™¯çš„èµ·å§‹å¸§å·
        scene_end: æ‰€å±åœºæ™¯çš„ç»“æŸå¸§å·
    """
    frame_index: int
    sharpness_score: float
    scene_start: int
    scene_end: int


class GPUFrameProcessor:
    """
    GPU åŠ é€Ÿçš„å¸§å¤„ç†å™¨
    
    ä¸‰å±‚æ¼æ–—æ¨¡å‹çš„å‰ä¸¤å±‚ (L1 ç‰©ç†å±‚ + L2 è´¨é‡å±‚) å®ç°ã€‚
    
    ç®—æ³•æµç¨‹:
        1. æŒ‰ sample_fps é‡‡æ ·è§†é¢‘å¸§
        2. L1: å®æ—¶è®¡ç®—å¸§é—´å·®å¼‚ (MAD)
        3. å½“å·®å¼‚è¶…è¿‡é˜ˆå€¼ï¼Œæ ‡è®°ä¸ºæ–°åœºæ™¯
        4. L2: å¯¹ä¸Šä¸€ä¸ªåœºæ™¯ï¼Œé€‰å‡ºæ¸…æ™°åº¦æœ€é«˜çš„å¸§ä½œä¸º"å† å†›å¸§"
        5. åœºæ™¯æŒç»­æ—¶é—´ä¸è¶³ min_scene_duration çš„ï¼Œè§†ä¸º"åŠ¨æ€ç‰‡æ®µ"ä¸¢å¼ƒ
    
    Attributes:
        diff_threshold: å¸§é—´å·®å¼‚é˜ˆå€¼
        min_scene_duration: åœºæ™¯æœ€çŸ­æŒç»­æ—¶é—´ (ç§’)
        sample_fps: é‡‡æ ·å¸§ç‡
        device: è®¡ç®—è®¾å¤‡ (cuda/cpu)
        laplacian_kernel: é¢„åŠ è½½åˆ° GPU çš„æ‹‰æ™®æ‹‰æ–¯ç®—å­
    
    Example:
        >>> processor = GPUFrameProcessor(diff_threshold=0.12)
        >>> for shot in processor.extract_best_shots(video_path):
        ...     print(f"Frame {shot.frame_index}, Sharpness: {shot.sharpness_score}")
    """
    
    def __init__(
        self,
        diff_threshold: float = 0.12,
        min_scene_duration: float = 1.5,
        sample_fps: int = 4,
        device: str = "cuda"
    ) -> None:
        """
        åˆå§‹åŒ– GPU å¸§å¤„ç†å™¨
        
        Args:
            diff_threshold: å¸§é—´å·®å¼‚é˜ˆå€¼ (0-1)
                - è¶…è¿‡æ­¤å€¼è§†ä¸ºåœºæ™¯åˆ‡æ¢
                - è¾ƒä½å€¼ (0.08-0.12): å¯¹å¾®å°å˜åŒ–æ•æ„Ÿï¼Œé€‚åˆé™æ€ PPT
                - è¾ƒé«˜å€¼ (0.15-0.25): å¿½ç•¥å°å¹…åŠ¨ç”»ï¼Œé€‚åˆå«åŠ¨æ•ˆçš„æ¼”ç¤º
            min_scene_duration: åœºæ™¯æœ€çŸ­æŒç»­æ—¶é—´ (ç§’)
                - ç”¨äºè¿‡æ»¤æŒç»­åŠ¨æ€å†…å®¹ (å¦‚ PPT ä¸­åµŒå…¥çš„è§†é¢‘)
                - å»ºè®®å€¼ 1.0-2.0 ç§’
            sample_fps: é‡‡æ ·å¸§ç‡ (æ¯ç§’å–å¤šå°‘å¸§)
                - è¾ƒä½å€¼èŠ‚çœç®—åŠ›ï¼Œä½†å¯èƒ½é”™è¿‡å¿«é€Ÿç¿»é¡µ
                - å»ºè®®å€¼ 2-6
            device: è®¡ç®—è®¾å¤‡
                - "cuda": ä½¿ç”¨ GPU (æ¨è)
                - "cpu": å›é€€åˆ° CPU
        """
        self.diff_threshold = diff_threshold
        self.min_scene_duration = min_scene_duration
        self.sample_fps = sample_fps
        
        # ========== æ£€æŸ¥ CUDA å¯ç”¨æ€§ ==========
        if device == "cuda" and not torch.cuda.is_available():
            logger.warning("âš ï¸ CUDA ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU æ¨¡å¼")
            self.device = torch.device("cpu")
        else:
            self.device = torch.device(device)
            if device == "cuda":
                gpu_name = torch.cuda.get_device_name(0)
                logger.info(f"ğŸš€ GPU å¸§å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ: {gpu_name}")
        
        # ========== é¢„åŠ è½½æ‹‰æ™®æ‹‰æ–¯æ ¸åˆ° GPU ==========
        # æ ‡å‡† 3x3 æ‹‰æ™®æ‹‰æ–¯ç®—å­
        # ç”¨äºè¾¹ç¼˜æ£€æµ‹ï¼Œæ–¹å·®è¶Šå¤§è¡¨ç¤ºå›¾åƒè¶Šæ¸…æ™°
        self.laplacian_kernel = torch.tensor(
            [[0, 1, 0],
             [1, -4, 1],
             [0, 1, 0]],
            dtype=torch.float32,
            device=self.device
        ).view(1, 1, 3, 3)
        
        logger.debug(f"âš™ï¸ å‚æ•°é…ç½®: diff_threshold={diff_threshold}, "
                    f"min_scene_duration={min_scene_duration}s, sample_fps={sample_fps}")
    
    def _frame_to_tensor(self, frame) -> torch.Tensor:
        """
        å°† OpenCV BGR å¸§è½¬æ¢ä¸º GPU ç°åº¦å¼ é‡
        
        Why ç°åº¦?
            å¸§å·®å’Œæ¸…æ™°åº¦è®¡ç®—éƒ½åªéœ€è¦äº®åº¦ä¿¡æ¯ï¼Œ
            è½¬ä¸ºç°åº¦å¯å‡å°‘ 3 å€æ•°æ®ä¼ è¾“é‡å’Œè®¡ç®—é‡ã€‚
        
        Args:
            frame: OpenCV BGR æ ¼å¼çš„å¸§ (numpy.ndarray)
            
        Returns:
            torch.Tensor: å½’ä¸€åŒ–åˆ° [0, 1] çš„ç°åº¦å¼ é‡
        """
        # BGR -> Gray (ä½¿ç”¨ OpenCVï¼Œæ¯” torch æ›´å¿«)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # numpy -> torchï¼Œå¹¶å½’ä¸€åŒ–åˆ° 0-1
        tensor = torch.from_numpy(gray).float().to(self.device) / 255.0
        return tensor
    
    def compute_frame_difference(
        self,
        frame1: torch.Tensor,
        frame2: torch.Tensor
    ) -> float:
        """
        L1 ç‰©ç†å±‚æ ¸å¿ƒ: è®¡ç®—ä¸¤å¸§ä¹‹é—´çš„å·®å¼‚åº¦
        
        ä½¿ç”¨ Mean Absolute Difference (MAD) ç®—æ³•:
            1. è®¡ç®—ä¸¤å¸§åƒç´ çº§ç»å¯¹å·®å€¼
            2. å–å‡å€¼ä½œä¸ºå·®å¼‚åˆ†æ•°
            3. è¿”å› 0-1 ä¹‹é—´çš„å·®å¼‚åˆ†æ•°
        
        Why MAD è€Œé SSIM?
            - MAD åœ¨ GPU ä¸Šè®¡ç®—æå¿« (å•æ¬¡å¼ é‡è¿ç®—)
            - å¯¹äºåœºæ™¯åˆ‡æ¢æ£€æµ‹ï¼ŒMAD çš„æ•æ„Ÿåº¦è¶³å¤Ÿ
            - SSIM è™½ç„¶æ›´ç²¾ç¡®ï¼Œä½†è®¡ç®—å¤æ‚åº¦é«˜ï¼Œä¸é€‚åˆå®æ—¶æµå¤„ç†
        
        Args:
            frame1: ç¬¬ä¸€å¸§ (torch.Tensor)
            frame2: ç¬¬äºŒå¸§ (torch.Tensor)
            
        Returns:
            float: å·®å¼‚åˆ†æ•° (0-1)ï¼Œè¶Šå¤§å·®å¼‚è¶Šå¤§
        """
        diff = torch.abs(frame1 - frame2).mean().item()
        return diff
    
    def compute_laplacian_sharpness(self, frame: torch.Tensor) -> float:
        """
        L2 è´¨é‡å±‚æ ¸å¿ƒ: è®¡ç®—å¸§çš„æ¸…æ™°åº¦å¾—åˆ† (Laplacian Variance)
        
        åŸç†:
            1. ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­å¯¹å›¾åƒè¿›è¡Œå·ç§¯ (æ£€æµ‹è¾¹ç¼˜)
            2. è®¡ç®—å·ç§¯ç»“æœçš„æ–¹å·®
            3. æ–¹å·®è¶Šå¤§ï¼Œè¯´æ˜è¾¹ç¼˜è¶Šé”åˆ©ï¼Œå›¾åƒè¶Šæ¸…æ™°
        
        Why Laplacian Variance?
            - å¯¹ç„¦è·/æ¨¡ç³Šå˜åŒ–éå¸¸æ•æ„Ÿ
            - èƒ½æœ‰æ•ˆåŒºåˆ†æ¸…æ™°å¸§å’Œè¿åŠ¨æ¨¡ç³Šå¸§
            - è®¡ç®—ç®€å•ï¼Œé€‚åˆ GPU å¹¶è¡Œ
        
        Args:
            frame: è¾“å…¥å¸§ (torch.Tensor)
            
        Returns:
            float: æ¸…æ™°åº¦å¾—åˆ† (è¶Šé«˜è¶Šæ¸…æ™°)
        """
        # æ·»åŠ  batch å’Œ channel ç»´åº¦: (H, W) -> (1, 1, H, W)
        frame_4d = frame.unsqueeze(0).unsqueeze(0)
        
        # GPU å·ç§¯è¿ç®—
        laplacian = torch.nn.functional.conv2d(
            frame_4d,
            self.laplacian_kernel,
            padding=1
        )
        
        # è¿”å›æ–¹å·®ä½œä¸ºæ¸…æ™°åº¦å¾—åˆ†
        variance = laplacian.var().item()
        return variance
    
    def extract_best_shots(
        self,
        video_path: Path,
        progress_callback: Optional[Callable[[int, str], None]] = None
    ) -> Generator[BestShot, None, None]:
        """
        ä¸»å…¥å£: ä»è§†é¢‘ä¸­æå–æ¯ä¸ªåœºæ™¯çš„"å† å†›å¸§"
        
        ç®—æ³•æµç¨‹:
            1. æŒ‰ sample_fps é‡‡æ ·è§†é¢‘å¸§
            2. å®æ—¶è®¡ç®—å¸§é—´å·®å¼‚ (L1)
            3. å½“å·®å¼‚è¶…è¿‡é˜ˆå€¼ï¼Œæ ‡è®°ä¸ºæ–°åœºæ™¯
            4. å¯¹ä¸Šä¸€ä¸ªåœºæ™¯ï¼Œé€‰å‡ºæ¸…æ™°åº¦æœ€é«˜çš„å¸§ (L2)
            5. åœºæ™¯æŒç»­æ—¶é—´ä¸è¶³ min_scene_duration çš„ï¼Œè§†ä¸º"åŠ¨æ€ç‰‡æ®µ"ä¸¢å¼ƒ
        
        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
                - å»ºè®®ä¼ å…¥è£å‰ªåçš„è§†é¢‘ä»¥èšç„¦ PPT åŒºåŸŸ
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
                - ç­¾å: callback(percent: int, message: str)
                - ç”¨äºæ›´æ–°ä»»åŠ¡è¿›åº¦æ¡
            
        Yields:
            BestShot: æ¯ä¸ªæœ‰æ•ˆåœºæ™¯çš„å† å†›å¸§ä¿¡æ¯
        
        Note:
            ä½¿ç”¨ Generator æ¨¡å¼æ˜¯ä¸ºäº†é¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å¸§åˆ°å†…å­˜
        """
        video_path = Path(video_path)
        cap = cv2.VideoCapture(str(video_path))
        
        if not cap.isOpened():
            logger.error(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return
        
        try:
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            # è®¡ç®—é‡‡æ ·é—´éš” (æ¯éš”å¤šå°‘å¸§å–ä¸€æ¬¡æ ·)
            sample_interval = max(1, int(fps / self.sample_fps))
            # åœºæ™¯æœ€å°å¸§æ•°é˜ˆå€¼ (é‡‡æ ·å¸§æ•°)
            min_scene_frames = int(self.min_scene_duration * self.sample_fps)
            
            logger.info(f"ğŸ¬ å¼€å§‹ GPU å¸§å¤„ç†")
            logger.info(f"   ğŸ“Š æ€»å¸§æ•°: {total_frames}, FPS: {fps:.1f}")
            logger.info(f"   âš™ï¸ é‡‡æ ·é—´éš”: {sample_interval} å¸§, æœ€å°åœºæ™¯å¸§æ•°: {min_scene_frames}")
            
            # ========== åœºæ™¯çŠ¶æ€æœº ==========
            prev_tensor: Optional[torch.Tensor] = None
            scene_start = 0                    # å½“å‰åœºæ™¯èµ·å§‹å¸§
            scene_best_frame_idx = 0           # å½“å‰åœºæ™¯æœ€æ¸…æ™°å¸§ç´¢å¼•
            scene_best_sharpness = -1.0        # å½“å‰åœºæ™¯æœ€é«˜æ¸…æ™°åº¦
            frame_idx = 0                      # å½“å‰è¯»å–å¸§ç´¢å¼•
            sampled_count = 0                  # å·²é‡‡æ ·å¸§æ•°
            total_scenes = 0                   # æ€»åœºæ™¯æ•° (ç”¨äºæ—¥å¿—)
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ========== è·³å¸§é‡‡æ · ==========
                if frame_idx % sample_interval != 0:
                    frame_idx += 1
                    continue
                
                sampled_count += 1
                
                # è¿›åº¦å›è°ƒ (æ¯ 10 æ¬¡é‡‡æ ·æ›´æ–°ä¸€æ¬¡)
                if progress_callback and sampled_count % 10 == 0:
                    percent = int((frame_idx / total_frames) * 100)
                    progress_callback(percent, f"GPU åˆ†æå¸§: {frame_idx}/{total_frames}")
                
                # è½¬æ¢åˆ° GPU å¼ é‡
                current_tensor = self._frame_to_tensor(frame)
                
                # è®¡ç®—å½“å‰å¸§æ¸…æ™°åº¦ (æ— è®ºæ˜¯å¦åˆ‡æ¢åœºæ™¯éƒ½è¦ç®—ï¼Œç”¨äºæ‹©ä¼˜)
                sharpness = self.compute_laplacian_sharpness(current_tensor)
                
                # ========== é¦–å¸§åˆå§‹åŒ– ==========
                if prev_tensor is None:
                    prev_tensor = current_tensor
                    scene_best_sharpness = sharpness
                    scene_best_frame_idx = frame_idx
                    frame_idx += 1
                    continue
                
                # ========== L1: è®¡ç®—å¸§é—´å·®å¼‚ ==========
                diff = self.compute_frame_difference(prev_tensor, current_tensor)
                
                # ========== æ£€æµ‹åœºæ™¯åˆ‡æ¢ ==========
                if diff > self.diff_threshold:
                    # åœºæ™¯ç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦æ»¡è¶³æœ€å°æŒç»­æ—¶é—´
                    scene_sampled_frames = sampled_count - 1  # å½“å‰å¸§å±äºæ–°åœºæ™¯
                    
                    if scene_sampled_frames >= min_scene_frames:
                        # æœ‰æ•ˆåœºæ™¯ï¼Œè¾“å‡ºå† å†›å¸§
                        total_scenes += 1
                        logger.debug(f"   ğŸ¯ åœºæ™¯ #{total_scenes} [{scene_start}-{frame_idx}] "
                                   f"å† å†›å¸§: {scene_best_frame_idx}, æ¸…æ™°åº¦: {scene_best_sharpness:.4f}")
                        
                        yield BestShot(
                            frame_index=scene_best_frame_idx,
                            sharpness_score=scene_best_sharpness,
                            scene_start=scene_start,
                            scene_end=frame_idx - sample_interval
                        )
                    else:
                        # æŒç»­æ—¶é—´ä¸è¶³ï¼Œä¸¢å¼ƒ (å¯èƒ½æ˜¯åŠ¨æ€è§†é¢‘ç‰‡æ®µ)
                        logger.debug(f"   â­ï¸ åœºæ™¯ [{scene_start}-{frame_idx}] è¢«ä¸¢å¼ƒ: "
                                   f"æŒç»­å¸§æ•° {scene_sampled_frames} < {min_scene_frames}")
                    
                    # é‡ç½®åœºæ™¯çŠ¶æ€
                    scene_start = frame_idx
                    scene_best_sharpness = sharpness
                    scene_best_frame_idx = frame_idx
                    sampled_count = 1
                else:
                    # åŒä¸€åœºæ™¯å†…ï¼Œæ›´æ–°å† å†›å¸§ (å¦‚æœå½“å‰å¸§æ›´æ¸…æ™°)
                    if sharpness > scene_best_sharpness:
                        scene_best_sharpness = sharpness
                        scene_best_frame_idx = frame_idx
                
                prev_tensor = current_tensor
                frame_idx += 1
            
            # ========== å¤„ç†æœ€åä¸€ä¸ªåœºæ™¯ ==========
            if sampled_count >= min_scene_frames:
                total_scenes += 1
                logger.debug(f"   ğŸ¯ æœ€ååœºæ™¯ #{total_scenes} [{scene_start}-{frame_idx}] "
                           f"å† å†›å¸§: {scene_best_frame_idx}, æ¸…æ™°åº¦: {scene_best_sharpness:.4f}")
                
                yield BestShot(
                    frame_index=scene_best_frame_idx,
                    sharpness_score=scene_best_sharpness,
                    scene_start=scene_start,
                    scene_end=frame_idx - 1
                )
            
            logger.success(f"âœ… GPU å¸§å¤„ç†å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {total_scenes} ä¸ªæœ‰æ•ˆåœºæ™¯")
                
        finally:
            cap.release()
            # æ¸…ç† GPU ç¼“å­˜
            if self.device.type == "cuda":
                torch.cuda.empty_cache()
                logger.debug("ğŸ§¹ GPU æ˜¾å­˜å·²æ¸…ç†")
    
    def get_frame_at_index(self, video_path: Path, frame_index: int):
        """
        å·¥å…·æ–¹æ³•: ä»è§†é¢‘ä¸­è¯»å–æŒ‡å®šå¸§
        
        ç”¨äºåœ¨ç¡®å®šå† å†›å¸§ç´¢å¼•åï¼Œä»åŸå§‹è§†é¢‘ä¸­æˆªå–å®é™…ç”»é¢ã€‚
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
                - åº”ä¼ å…¥åŸå§‹æœªè£å‰ªè§†é¢‘ä»¥è·å–å®Œæ•´ç”»é¢è´¨é‡
            frame_index: å¸§ç´¢å¼•å· (0-indexed)
            
        Returns:
            numpy.ndarray: BGR æ ¼å¼çš„å¸§æ•°æ®ï¼Œå¤±è´¥è¿”å› None
        """
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            logger.warning(f"âš ï¸ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return None
        
        try:
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)
            ret, frame = cap.read()
            return frame if ret else None
        finally:
            cap.release()
